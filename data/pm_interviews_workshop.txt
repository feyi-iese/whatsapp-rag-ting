Meeting Notes: Product Management Interviews Workshop
Date: June 8, 2025 (17:00-22:00)
Host: Satish Mummareddy
Attendees: Feyi and 893 others

Summary:
### Product Management Fundamentals

- Core PM role: Orchestrate building successful products aligned with company/org mission
- Key PM activities:
  - Strategy (20-30%): Identify and align on product opportunities
  - Execution (40-50%): Build, test, launch, grow and sunset products
  - Leadership (20-30%): Enable team’s long-term success
- PM Role Types:
  - Generalist: Consumer growth, business products (highly competitive)
  - Semi-specialist: Trust/safety, privacy, internal tools (less competitive)
  - Specialist: Ads, search, infrastructure, hardware (requires deep domain expertise)

### Interview Focus Areas

- Product Thinking: Can identify right features/products to build
- Analytical Thinking: Can set clear goals, track progress, make decisions
- Leadership: Can build/support strong teams
- Technical Understanding: Can influence technical products strategically (for technical roles)
- Interview Styles:
  - Prospective: Future hypothetical scenarios (Google style)
  - Retrospective: Past experience based (Amazon style)

### Product Thinking Framework

- Context & Motivation: Understand market dynamics, opportunities, risks
- Target Audience: Identify valuable customer segments to focus on
- Problem Identification: Determine high-value problems worth solving
- Solution Development: Create compelling solutions that solve problems
- Segmentation Approach:
  - Single factor: Basic division (e.g., primary vs investment home buyers)
  - Two factor: Layer additional criteria
  - Three factor: Complex but comprehensive segmentation

### Analytical Thinking Components

- Goal Setting & Metrics:
  - Define success in plain language
  - Choose measurable metrics that reflect goals
  - Consider aggregate, customer-centric, and partner-centric metrics
- Debug Product Issues:
  - Conduct root cause analysis
  - Segment data to locate problems
  - Generate and validate hypotheses
  - Design and test solutions
- Product Trade-offs:
  - Create clear decision frameworks
  - Evaluate options against criteria
  - Consider quantitative and qualitative data

### Leadership Skills Assessment

- Proactiveness:
  - Identify opportunities independently
  - Take initiative to develop plans
  - Get volunteer support
  - Secure resources
- Ownership & Accountability:
  - Bring clarity to goals/plans
  - Do whatever necessary for success
  - Take responsibility for outcomes
- Conflict Resolution:
  - Address issues early
  - Facilitate open communication
  - Manage emotions effectively
  - Drive alignment

### Cross-Functional Partnership

- Build empathy for different functions’ perspectives
- Establish clear working models with partners
- Adapt communication style to different levels
- Create space for others to shine
- Share credit and visibility
- Enable team voice in product direction

### Interview Communication Skills

- Separate thinking time from speaking time
- Practice structured communication
- Demonstrate intellectual honesty
- Manage interview time effectively
- Help interviewer follow along and take notes
- Handle difficult interviewers professionally

### Mindset & Resilience

- Address saboteur mindsets:
  - Identify negative patterns
  - Practice radical acceptance
  - Focus on actionable steps
- Handle rejection constructively:
  - View career as stepping stones
  - Focus on controllable factors
  - Learn from each experience
- Manage interview emotions:
  - Prepare thoroughly
  - Focus on present moment
  - Give best effort regardless of circumstances

Transcript:
Them: The third housekeeping thing is people that wanna keep asking this question, is gonna be a live only session. I'm not gonna share recordings of this so being very clear about that. And then there's a question about, hey. Like, can we take screenshots? Please do not take screenshots. Of the content. Take your own notes. Like, whatever strikes you, take your notes. Okay? And then please don't share screenshots. Of the material. I actually, like, am sharing material that I teach in my paid course. I'm not actually I don't hold back things. So please respect that. Okay. So that's actually, like, my ask with respect to housekeeping. Cool? I'm just trying to see okay. Does anybody have, like, are is everybody having audio issues from me? Or is it just Cool. I see a lot of audio is clear, gonna check assume that it is good. Cool. So so I was experimenting with those Zoom's watermark features. That's why your email is showing up. If it is too disruptive, we'll figure that out. Cool. It is 08:10 So let's get started. I'm gonna ask one bit of assistance from from people. If somebody asks, hey. Can you share the regional ring? Somebody else, can you just, like, paste it back in the chat for people? Okay. So let's get started. This is gonna be a five hour workshop. Gonna be in dense, so let's get started. So when you're thinking about PM interviews, the place that I always want to start with is by restating what is the role of a PM. And then how the interview process maps to that. Okay. I think that the that's the first place that I want to start with. Okay. So here's how I view the role of a product manager. The role of a product manager is to orchestrate building successful products that are aligned with the company or orgs mission. You can't build any product that you want in the world, but you have to build from a subset of products that would map to a company's or your own org's mission And you build successful products by solving impactful customer and business problems, and you don't actually build anything on your own, you are actually, like, leveraging the strengths of the entire team to build success with Box. So PM's role boils down to orchestrating building successful products that are aligned with an augur company's mission that solve impactful customer and business problems by maximizing the strengths of the entire team. Okay. So if you are given a team, you wanna actually, like, get the most value out of that team for your company and for your customers. And that's what the role of a PM is. And what activities do PMs do on a day to day basis? Usually, it is a mix a portfolio, and it's a mix of strategy work or product strategy work, which is identifying and getting alignment on new product opportunities, Execution, which is building test launching, growing, and shutting down products. Or product features, and then leadership which is setting the team up operate independently of them to have long term success. Okay. That is what is a mix of activities that PMs do on a day to day basis. Based on the life cycle of the team, and where they are in actually, like, the product cycle as well. The mix changes between how much strategy work you're doing, how much execution work you're doing, and how much leadership work you're doing. But it's a mix of those three things. And then what are the different types of product manager roles? So there are roles like consumer growth, business privacy, internal tools, ads, search and recommendations, developer tools, infrastructure, and hardware. And some of these roles are generalist PM roles, like consumer growth and business products. But they're highly competitive. And they require people to have consumer product experience. And then there are other roles like trust and safety, privacy, and internal tools. Which are mostly generalist PM roles, but they're less competitive and may require some amount of trust and safety and privacy experience on the tier of company that you're looking for. And then there are ads, search and recommendations, developer tools, infrastructure, and hardware. Which are specialist PM roles, where people either need to be more technical or they need to have deep domain knowledge about those areas. Okay. These types of PM roles cover mostly, like, 80 to 90% of types of PM roles that exist. This is not completely exhaustive, but it gets 80, 90% of actually, like, the PM roles that are there. Type of experience people might be looking for and how competitive they are. And then what are PM interviews trying to do? PM interviews are trying to evaluate for the thing job that they're actually being asked to do. Which is can they identify the right features or products to build, which is what product thinking is, Can they set clear goals, track progress, and make the right decisions? Which is what analytical thinking is? Can they build and support strong teams which is what leadership is. K. And then for the technical roles and then, like, the specialist roles, they're trying to understand if PMs can have strategic influence on deeply technical products is what technical understanding is. And if they can't have strategic influence on products, which is actually, like, what domain knowledge is. Okay. So that's what they're trying to evaluate. And product thinking, analytical thinking, and leadership all companies, all roles, evaluate for them. And then technical understanding, specialist roles, and some companies evaluate for that. And domain knowledge is evaluated for specialist roles. Okay. That's what people are actually trying to evaluate you for interviews. Okay. They're just trying to see if you do the job that you're supposed to be doing. And then what are the different types or styles of interviewing? So it's prospective style interviewing, there's retrospective style interviewing or behavioral interview. K? So prospective style interviewing was started by Google and now is used by most top tier companies. In prospective style interviewing, people don't about your past experience. When it comes to evaluating your product thinking and analytical thinking skills. They ask you about what products you have built. Evaluate your product thinking skills. They're just gonna say, hey. If you work on any product that we think of, what are you gonna build? It could be about my own company's products. I'm Google, I can ask you about search, ads, like, about Google Workspace. I can ask you about any product. And I want you to tell me what you would build. How would you set goals? How would you make decisions for those things? Or I could ask you about in the as a I can ask you about DoorDash. Ask you about Spotify. I can ask you about any number of general consumer products out there. Okay. That is what prospective interviewing is. And even companies that do prospective interviewing for product thinking and analytical thinking, they do ask about your past experience, evaluate your leadership skills. Accept and relationship skills. Okay. And this allows companies to consistently evaluate candidates. And it also allows interviewers to be consistent among each other. Okay. Google started it, and now all of the top tier companies use it. Except Amazon. And before Google started prospective interviewing, all product companies would you would do retrospective style interviews or behavioral style interviews. And a lot of companies still do behavioral style interviews. Over here, people are trying to ask questions about your past, to evaluate your product skills as well as your analytical skills leadership skills. They can ask questions like, hey. What is the most impactful product you worked on? What was the most challenging product you worked on? That simple question can then be used to evaluate your product skills, your analytical skills, and your leadership skills. And that's what behavioral style interviewing is. Okay. And it is all based on your past experiences. And based on what companies you're interviewing for, you'll would and some companies are gonna do pure retrospective, and some companies are gonna do prospective interviews. And you need to actually, like, be prepared for both of those. Then the let's talk about each of these of interviews. Okay. So what are people trying to evaluate you in product thinking interviews? They're trying to evaluate if you can actually, like, develop an effective product strategy for a problem area. So if we just, like, gave you an ambiguous space, will you be able to, like, figure out what is the product that you should be building in that? And that's what product thinking interviews are typically about. It could be as, like, open ended question like, hey. You're a PM on IG app. You've been put in charge of building a new product area to invest in. Dating, what would you build and why? And in thirty minutes, you need to go from this prompt to like, a description of what a what product you would build and then maybe mark it up. Using a wireframe on the board or any of those things. Okay. So that's what a prompt. And what are people And then I'm, like, showing you some other examples of of different types of things. How could you like, revenue of perplexity. How would how do you reinvent shopping ads? Any of these things. People can ask you, questions about a wide spectrum of consumer products. And then what are people trying to evaluate? They try to evaluate you can apply rigorous product thinking to come up with a cohesive product narrative while collaborating well with the interviewer. And in thirty minutes. That's what people are trying to evaluate. And what does rigorous thinking mean from a product thinking perspective? Can you understand what is the context for that product space, the market, the company, the competitors that determine what we should be focusing on at this point in time. Can you like, frame the product motivation and context well? Can you determine who is the right audience to build for in that space? Can you identify and prioritize the right problems? And then can you come up with solutions that solve the problem and are compelling to build? And are you doing the work of all of these pieces? Do I come up with the right to build? And that's what rigorous thinking is. Okay. So you are going through the thought process to actually get get at a solution. Versus instinctively just picking what some idea you have about what you wanna build. That's what rigorous thinking is. And then what is a cohesive narrative? Cohesive narrative is when the product's purpose ladders up to a company's orgs a company's org mission, The rationale for the product aligns with the company's strengths and the industry gaps. The segmentation aligns with the product space. The problems align with the segments. The solutions align with the problem. And the solution is elegant. And that's what a cohesive narrative is. Everything actually flows together. K. And then what are communication skill collaborative skills in an interview context? Like, can you communicate in a structured and clear manner so that the interviewer can follow you along? Do you un explain the underlying thought process and rationale for the decisions that you're making? Can you address the feedback that people are giving you an intellectually honest manner? And then do you manage your time well? To do all of this in thirty minutes? And that's what interview collaboration skills are all about. K. And what is a good interview? A good interview is when applies rigorous thinking, comes up with a cohesive narrative, and demonstrates strong collaborative skills within a thirty minute block. If you do that, you've had a good interview. And then what is a great product thinking interview? In addition to doing those things, the person comes up with unique insights. About the market dynamics and the problem. People think that great interviews are about using some creative solutions where they're using also technology. Stuff and then something that nobody has thought about. But that's not actually, like, what makes great interviews. Great interviews stem from people having unique insights about the and customer problems. That's the seed. And then they're actually, like, doing first principle thinking about segmentation. And the segmentation feels very native to the product space. And then if they truly understood the segment well, they had unique insights about the problem, then they can come up with solutions that the problem really well deeply in the most efficient way. Okay? They try to leverage the technology and ecosystem changes that are happening at that point in time. And the interviewer leaves thinking that, hey. I learned something. They either actually, like, feel that I learned something new about this product space that I didn't think about, or they're like, I wish I had thought about that. And when the interviewer feels that, that's a great interview. Okay. And great interviews don't happen all the time. And you don't have to have a great interview to actually get hired. Can have a very solid interview and actually get hired. But I and but I just want you to understand what a great interview is. People try to go for a great interview and I'll as a result, make a ton of basic mistakes. They try to come up with some cool solution that does not actually, like, have a very cohesive narrative. Does not solve the problem that the customer has. Does not actually, like, identify the right segments, because they wanna do some cool thing. Because they think that's what makes a great interview. Okay. You need to first have a solid interview and then actually, like, the great part of it comes from truly understanding the market well. Okay. So that's what I want you to take away from this slide over here. Then for analytical thinking, I am actually going to do one quick thing. And my mouse seems okay. Yep. Cool. I'm gonna use the slides over here. So here, what people are trying to do with analytical thinking is is this person going to make principal decisions during execution? 90% of companies don't rigorously make decisions. There's a lot of gut instinct opinions based decision making that happens. So what companies are trying to evaluate, at least the top tier companies are, evaluating is do does this person make principal decisions? And what does it actually mean to make principal decisions? So there's a bunch of types of decisions that we make during execution. The first decision that we make when we're executing is setting goals and choosing metrics for the products that we are building. Okay. That's one. The second thing is you have to prioritize opportunities. You have you you could build a bunch of things. Which ones do you build? What do you build? You have to prioritize those opportunities. And then when you start building, the data will show something. And you have to figure out from that What is the actual product issue or marketing issue or any of those issues and how do we go about solving those things? So you build something, you get some data, and you have to figure out what is the product change that you have to make. So that's what debugging product issues from metrics are about. And then or do you actually, like, do that principally, or do you just, like, throw ideas at the wall? Or you are building a product, and then you have trade offs with different things in some form. Once you have a slightly larger prod product, there are competing interests and there's one thing moves up, the other thing might move down. How do you actually, like, deal with that in a principled way? Instead of getting territorial and fighting with people? And then you can't AB test everything. So you have to make decisions by thinking through what the implications of a particular product change are, and that's what product simulation is about. Okay. And what are the types of interview questions that you get for these types of things? For setting goals and choosing metrics, you might get open ended questions that, hey. You have the PM for product x. What goal would you set, and what metrics would you use to measure success? And then for prioritizing opportunities, you all seen estimation questions. You might not be asked to estimate revenues, revenue or top market sizes. You might be asked to estimate reach. The number of people who might actually, like, be interested in this. Engagement or action type estimations, and you can actually, like, do estimation for these things. And then by doing estimation, you can then prioritize one opportunity against the other. And that's why they're asking these questions. And then the third type of things, as I said, is debugging product issues based on metric stress. Trends. So you might notice some interesting fact. One side of the marketplace is growing faster than the other. Men on Tinder is growing, but women are not. Okay. You see that data point. What do you do about it? Okay. One segment of the marketplace is successful while others are not. National brands are getting a lot of sales. While artisan stores are not. What would you do? You see that data point, but now what do we do with the product? Okay. So those are the types of questions that are about debugging product issues based on metrics, friends. And then there is product and metrics trade offs. Usually, you have multiple fee features in a product one feature is growing and is impacting the other feature. What do you do? Let's say at Spotify, engagement on music is down, but podcast is going up. What do you do? And products can be used in different ways. What do you prefer? IT reels. Would you want hundred reels with 1,000,000 views or 1,000,000 reels with views? Product growth and integrity trade offs. Like, you put in some bullying filters, removing, like, nine, like, nine 20% of legitimate content. Is that okay? Okay. So those are the, like, product and metrics trade offs. And then there's, like, product simulation. You can't actually, like, test everything. So you have to think through what might happen if you made some changes. Should YouTube put ads at the beginning of a video or the middle of a video? Should Instagram stories be twenty four hours or forty eight hours? Should Facebook force people to add photos during profile creation? How do you actually, like, set up a decision for those kinds of things? Okay. So all of these are the types of decisions that you make when you're building products. Now can you make principal decisions on these things or are you just going actually, like, make gut instinct decisions? Because somebody felt so? And that's what analytical thinking is, and that's what people are trying to evaluate in these interviews. Okay. Then leadership interviews. What are people doing to evaluate? Like, PMs need to lead a group of people who they have no authority over. And you need to, like, lead them to take on challenges and win consistently. Does this person have that skill? Okay. And the way that they evaluate you is to ask a bunch of questions about your past. Tell me a time when you did this. Tell me over a scenario when this happened. If x happened on your d, what would you do? So you get these kinds of questions. The fundamental thing to understand is what are people trying to really understand? In this in through these questions? So different companies have different names for the leadership skills that they want to actually evaluate for. But there's, core set of things that people are trying to evaluate. They might name them different things. Amazon has a leadership principle Like DoorDash has a leadership principles. Roblox has a leadership principles. But at the core, there's some com common set of principles that they're trying to actually evaluate. And I'm using one of the frameworks of actually, like, doing it. And what people are trying to evaluate is is this person proactive in identifying opportunities, different types of opportunities? Does this person take ownership and accountability of outcomes? Is this person resourceful and resilient in driving results? Can this person resolve conflict? Can this person grow themselves and their team continuously? These are core leadership skills that PMs need and different companies might slice them in different ways and name them different things. Okay. And what do you get in a leadership interview? You probably get six to 10 questions, and each question is measuring one or two types of leadership skills. And then people score them, And then they're actually, like, saying, okay. Hey. Here's what their leadership skills are across each of these, and then they're actually, like, seeing whether it's a higher or no higher. And the fundamental thing is that there are set of things that our table stakes to be a PM. You can't do those things, you shouldn't be a PM. Okay? If you don't have those skills, you be a PM. And those skills, are basically ownership and accountability. If somebody does not take ownership and they don't feel accountable for the results that they're that they're supposed to be driving, they should not be a PM. Different job. So it's like table stakes to actually, like, be a PM. PM's fundamental job is to actually get a group of people to work together and accomplish something. Resolving conflict is like a core skill that they need to have. Don't have that, can't be a PM. You'll be out of a job on your team very quickly if you can't actually resolve conflict. And then you should be growing, and you should be helping your team grow together. And those are, like, table stakes skills for a PM. At least at the top tier companies. And you need to, like, have those skills to to actually, like, have a shot. Then there are skills that are game changers. For PMs. And that's proactiveness where people take initiative They're not waiting for somebody to tell them what to do. They're actually, like, identifying opportunities in the company for people, process, product opportunities, and then leaning into them into those opportunities. And that's proactiveness. And then they're resourceful and resilient. They make something out of nothing. They see an opportunity. And they're proactive in leaning into it. They have no resources for it. They somehow figure out a way to get somebody to scrappily make some prototype, somebody to some time into it, define some partners, They get some buying. Make something out of nothing. And that's resourcefulness. And then nothing works according to plan And when the dip comes, do they work through that and are resilient to come to onto the other side? And those people who are proactive, who are resourceful, and who are resilient, and who have, like, stories to tell about that, are game changers. In a leadership interview, a lot of times, it's like, hey. The good is okay. Yeah. This person seems fine. This is a safe hire. Versus there's, like, somebody who's made something out of nothing and is looking for opportunities to make the company better. And those people stand up. Okay. That's what makes great leadership interviews. So how do you prepare well for interviews? K. This is what people are evaluating you for. Like, how do you prepare well for interviews? The starting point to figure that out is what determines your interview performance. So the two parts to what determines your interview performance. The first part of it is what are your baseline product interview skills? Which is a green line, And then is the company and interview day variance? Okay. So for example, I have some baseline sets of skills. If I go and interview with a media company, any media company, I'm going to, like, be at my a, like, a plus plus game. If I go and interview for a financial services company, I'm not gonna be that great. Okay. It's not my strength, like, relatively. That's, like, company based variance. What is interview day variance? I slept perfectly well. Everything is actually, like, going well. I had, like, no traffic. I got on time. I had everything planned. Like, everything is going perfectly. That's interview day variance. I just all the interviewers are actually, like, super nice people. They had great days. They were super nice to me. Everything was on time. Great. I the other thing would be that I have, like, extreme back pain. I couldn't actually, like, sleep at night. I was stuck in traffic. I'm running ten minutes late to the interview. Like, the interviewer is fighting at home. They bring back to the interview. They are pissed off. Then half paying attention. Interview day variance. Okay. So those are the things that actually, like, determine your interview performance. Your baseline product and interview skills, and the company and interview day variance on top of that. That's what actually determines how well you do in an interview. So I wanna talk about actually, like, my past like, baseline and and variance in some form. 02/2011, I've been a engineering leader up to that point, and I was making my transition into into product. I had some baseline skills. I spent a year taking time off and actually just thinking of consumer products. So I've done, like, some variant of generalist consumer PM. Prep. Year. I had some baseline level of PM skills. And I interviewed with only two companies. Google and Yahoo. Google, I went seven rounds. Made one interview mistake. Below my level. Didn't get that offer. Yahoo, I did decently well. I got that offer. Work your three years for for at Yahoo. And worked on a few products. My baseline product skills improved. Okay. And then my dream company was Fitbit. And I had an 8AM interview with the head of product. And I completely tanked it. Like, I was sleep deprived. They asked me only one question. How do you do scum on your team? That that was the only question that I actually, like, got. I'd rambled for twenty five minutes. And they didn't wanna talk to me anymore after that. Did not actually, like, get one more phone phone call from Fitbit. But then I did, like, six or seven rounds at YouTube, Again, one thing that I screwed up, I didn't get that job. I did extremely well at Yelp. Got that job. Three years of working on on on on really amazing products at Yelp. My baseline skills were significantly higher. And I've done a lot of prep for Uber and Meta. I crossed both of those. And I got both of those offers. Six years of working at Meta on a wide variety of problems, I think my product skills are somewhere here. I've also, like, done a bunch of work over the last year. But if I didn't do solid preparation for the company that I was interviewing at, there would be a lot of variance around that even today if I interviewed. And if I did solid preparation, I would have my baseline skills would be, like, slightly higher, I'd have tighter variance around actually, like, my baseline skills. If I actually, like, did that. That's how I view my baseline skills and actually, like, company variance and interview the variance playing along with it. And I'm gonna ask you all to just, like, read this slide. Just read this slide. And we'll, like, talk about this. It's a it's a quote from Richard Feynman, who's supposed to be one of the greatest scientists. He has a book called, surely you're joking, mister Feinman. Just read this. Can you all see my slides?  
Me: Yes.  
Them: Awesome. Yeah. Just read the slide. Okay. I'm hoping you all read it. This is fundamentally what interviews all about. The people who do well in interviews don't do well in interviews because they're geniuses. They do well in interviews because they've been they're prepared. And what does preparation mean? Exactly what Feynman is talking about here. If I ask you right now, hey. You are the CEO of Perplexity. What products are you gonna build? And I put you on the spot and ask you to do that in thirty minutes. There's gonna be a very clear difference between two types of people. People who have thought about what perplexity should have should be doing and have thought about that problem, versus people who have not thought about that problem. It's gonna be a very bimodal set of of outputs that I'm gonna see. The people who have thought about this problem are actually gonna do significantly better than people who are thinking about this problem for the first time. The first time you think about any problem, you're gonna have a shitty first draft of your ideas. And if you do that in your in the interviews, you're not gonna perform well. At the top tier interviews. And if you have thought about problem, and if that there's there's, like, filters that are sitting in your brain, and you're asked to solve it in thirty minutes, you're gonna crush That's fundamentally the difference in interview preparation for people. Okay. So how do you improve your baseline product and analytical skills? So here are the things that you actually, like, need When you think about product and analytical skills, in companies that are doing proactive interviews, they're expecting you to be a generalist consumer PM. What it means is that they can ask you about any product from a wide variety of common consumer products at that point in time, in history, and you are supposed to be able to, like, do good product thinking and analytical thinking for them. Okay. So that's what people are expecting at the top tier companies and interviews. So if that is what the expectation is, how do you improve your baseline? And the way that you do that is that you need to develop industry knowledge, You need to improve your clarity of thought. You need to be able to do speed thinking where you can get to really high quality thinking in thirty minutes You need to be able to communicate that very crisply in an interview. You need to be able to collaborate with the interviewer, and you need to be to put it all together. And how do you do that? How do you actually, like, get better at these things? The way that you do improve your industry knowledge, that you actually, like, read and listen to a lot of industry in in topics about products. Like, understand market dynamics for different industries. You wanna actually, like, think about what the companies are doing, what the competitive landscape looks like, what are the user trends in a particular industry, And you wanna be able to, like, look at the product road map for specific companies and their competitors. And then you wanna understand the interview process for different companies. And that's what industry knowledge is. And you wanna put in the work to and to get better to build a baseline of knowledge that is valuable to you. And then how do you improve your clarity of thought? The way that you improve your clarity of thought is by doing deep writing practice. Okay. When people think about preparing for interviews, they wanna just go and do mock interviews. But what people really need to start with is by doing writing practice. And the way that you do writing practice that you wanna do you you wanna, like, give yourself, hey. Like, if I had eight hours to solve one problem, what would I write? And you wanna actually, like, write a first version of it in, like, in, like, four hours, leave it for an hour, come back, and then rewrite that. You'll see all the flaws in your thinking, and you'll actually, like, improve that. And that's what deep writing practice is. And then if you do a lot of these deep writing practices, you start to actually get much more efficient at doing that. So you can actually, like, do deep writing practice for a product in, four hours. And do a reasonable good a good job with it. And then you do it in two hours, and you do a good job with it. And then within that, you wanna, like, spend some amount of time doing market research and product research. Collect some information, and then do your writing about product thinking. And if you have thought deeply about a particular space, then you can actually practice speed thinking. And the way that you practice speed thinking is, again, by doing speed writing. Instead of actually, like, writing the response for what would you build for IG in, like, four hours, Now try to write that in thirty five minutes. Okay? And the way that you do it is you start writing in in, like, two hours, write it in one hour, write it in thirty minutes, And then if you wanted to, you can even do a full product thinking response in fifteen minutes. And then you can do the same thing for analytical thinking responses. You start by doing a question in thirty minutes, reduce it to fifteen minutes, ten minutes, and five minutes. Leadership, you write a response in, like, thirty minutes, and then you reduce it to ten minutes, five minutes, and then one minute. And that's how you improve your speed thinking by doing speed writing. And then if you have to, like, improve your communication, your interview communication, you need to work on being a % present in the moment. Among the 900 people who are here right now, how many of you do you think you're % present and the only thing you are paying attention to is my words? I bet you it is actually, like, pretty low.  
Me: Mine is here.  
Them: Because your mind is drifting someplace else. Okay. If you have to communicate well in an interview, you need to be a % present in the moment and be able to shut out everything else. You have to shut out worries about how you are actually doing in this interview. What is the interviewer thinking about me? Did I do well in my previous interview? All of those noise that's there, you need to able to shut that down and actually be able to focus on this very specific moment. And that is what being a % present is. And then need to be able to listen to what the interviewer is telling you. A lot of times, people don't even understand what the question was, and then after the interview, they think, oh, I answered the wrong question. I was one of those people at some point in time. Or the interviewer is giving you feedback in the interview, and then people won't pay attention to that. And then afterwards, they think, oh, they were trying to tell me that, but I didn't to it. I'm arguing about something else. Or people don't speak precisely and the interviewer struggles to actually absorb what is the real that this person is trying to say. And you want to work on those kinds of communication skills. And you can do that by actually, like, trying to practice thinking and then speaking. By doing writing plus speaking practices. And then you record yourself, and then you play it back, and you give yourself feedback. And then how do you, like, collaborate with the interviewer with intellect honesty? A lot of times, people operate out of fight or flight mode. When they get feedback, they either say a quick yes or they say a quick no to the interviewer. Because it comes from a place of fear. If they that they have to prove that they're right, then they're gonna say you're wrong to the interviewer. Are they just gonna keep defending what their position was? Or if they're scared of the interviewer, they might just agree with the interviewer. And try to people please them. Both of those are intellectually dishonest. And the thing that you really want to practice is intellectual honesty, which is you have a mental model for your response. Now somebody is giving you new bits of information. If you add added that information into your process, would your response change? And once you have done that work, and you've come at an answer, then you can say, hey. I've talked through this additional bit. And as a result of that, I'm either gonna change my position or I'm not gonna change my position. And that's what intellectual honesty is. And you have to practice that. And then you wanna put it all together where you've done deep thinking, you're do doing speed writing, You're actually, like, communicating clearly. You were practicing intellectual honesty, and then you wanna put it all together. Actually, like, a full interview. Then you can actually, like, go in the new mock interviews. That's how you break down all of the skills and then rebuild them into a better version of you and then go and then do mock interviews. That's how you improve your baseline product and analytical thinking skills. Okay. So industry knowledge, reading and writing, clarity of thought, do long deep writing that you edit again, Speed thinking, you do it by speed writing. Communication, you need to practice presence, listening, speaking. Collaboration, you need to practice intellectual honesty. And then putting it all together, you can do full verbal interviews on your own first. And then go on the next, like, do mock interviews. And then how do you improve your baseline leadership, x, f, and m behavioral interview? Things? You wanna build a storied portfolio of your leadership experiences. Okay. You have to if you wanna actually tell stories, need to actually, like, live stories. Okay? If you want to show that you were proactive, you need to actually be proactive. So start building your portfolio of stories that you wanna tell in the future. You wanna tell an accountability and ownership story? Like, be accountable for something today and then make something happen. You want to, like, tell a story about self growth? Identify opportunities, actually do it. If you wanna grow your team, find somebody who needs help and help them and actually grow at their skills. And then you need to actually, like, go identify stories, from your past actually build a portfolio that is worth telling You need to write your stories you can be crisp about how you're gonna communicate them. You need to learn how to speed write your stories so you can actually stay on track in interviews. And you need to figure out how do you tell stories verbally, you know, in a in a highly, communicative way. And you need to put it all together. We have to answer six to eight questions back to back, and still stay disciplined. And you wanna actually, like, practice each of these things. Again, like, common ways of actually doing it, I kind of flip through these things. So if you wanna build a story portfolio, start embodying leadership principles now. And then you wanna curate your stories for different types of of leadership skills. Find the story that actually, like, best tells that in a compelling way. When you identify a story, write down that story in a way in which the interviewer can actually pick out the skills that they you're trying to tell them you have. And then practice writing a story in short arcs. And then have to tell the story in a compelling way, and we'll talk about this. And then you do full verbal interviews where you answer six to eight questions back to back. Cool? And then how do you reduce interview day variance? So what are the things that get in the way of actually, like, having a great interview on the interview day? Thinking on your feet. You might get asked questions that you didn't think in the past or you don't know the answer to. How do you actually, like, get better at that? Depth of thinking. If you're into the unfair thing about PM interviews is that if you are interviewing at a particular company, at the top tier companies, the expectation is that you already know everything about the company, and you should act as if you were a PM at that company. So you need to be able to, like, think deeply about the company that you're trying to interview for. And then in companies, might try to evaluate same but they might have different interview styles. And then there's, like, key context that you need that you need to have loaded into your memory to be able to do well in interviews. And then there's uncertainty with a bunch of different logistics actually, like, plan for that. So if you actually, like, reduce logistical issues screwing up your interviews. And then need to have contingency plans because no interview is gonna go according to plan. And you can actually do a bunch of things to actually, like, tackle all of these things. If you wanna get better at thinking on your feet, you need to do wide spectrum riding practice. Like, here is a list of 50 different product types. And you should take, like, 20 of these and then do writing practice on them. If you did writing practice on 15, 20 products, these things, you are gonna I didn't your brain is gonna have a bunch of filters for different patterns of products and you will be able to answer a new question thrown at you much better. If you wanna do if you wanna improve your depth of thinking, you have to do 10 x preparation for the company that you're interviewing at. If you are interviewing with any company as a PM, you should spend, like, ten to twenty hours researching deeply about the market, the context, the the products that they are building, competitors' products, would you build for them? You need to actually go super deep. For company. If you're actually trying to get a job at that company. I would when I was interviewing at Meta, I took all of Meta's products and did, like, practice on almost all of them or different types of products at least. And then every company has different nuances of how they interview and you need to actually, like, figure out how that works. By talking to the recruiters, people who have done interviews at those companies, and then act like, adjust a little bit for that. So for example, if you're interviewing at Amazon, you should use the exact terminology that they use for the leadership principles. And you should change your stories to actually, like, use those words. Okay. What actually adapting to interview interview styles is. And then you should always have, like, a key context document you write. Every time I interview for a company, I have, like, a six to 10 page document about that company. And then I had a one page version of that, And the six to 10 page version, I read it the night before when I wake up in the morning. And the one page, was seated reading in the lobby. I want the context to be loaded in my mind actually, like, going in an interview. And then you wanna reduce uncertainty. You wanna find your logistics. If it's on-site interviews, I would do the drive the day before and actually check it out that I know where I'm gonna go. Where am I going to park? How much time am I gonna need? If it's videos like Internet backup phones, like we where is it actually gonna hit me on my face? When I'm sitting at my desk? Okay. What clothes am I gonna wear? What is the timing gonna be? What is my breakfast? What are the snacks I'm gonna take? What is my sleep routine? What is my my wife's job in actually, like, this interview process? Okay. You wanna, like, do all of that to reduce uncertainty. Okay. And then you wanna have contingency plans when things go wrong in an interview. Hey. One interview goes wrong, What am I going to do? If I knew the answer to that, I won't be panicking in the next interview. If I if I have a simple thing. If I actually don't do a a question while in interview, I'm just gonna go home, write a written response, then send it to the recruiter. Either irrespective of whether they see it or not. But that's my plan. If I know that is what my response is gonna be, if I screwed up a question, I don't have to worry about that question in the next interview. Pay a % attention in the next interview. And then deal with this later. And that's what contingency planning is. If I'm doing a product thinking question, and I screw up my segmentation, what am I gonna do? I'm gonna redo my segmentation. If I'm, like, doing problems and then realize that my segmentation is wrong, I can always back track to that checkpoint. If I knew that was what my response was gonna be, I'll be calm. When I up in an interview. And that's what contingency planning is. Cool. That's how you reduce interviewer maintenance. Thinking on your feet you improve by doing wide spectrum speed writing practices. Deep thinking, you need to do 10 x preparation for the company that you're interviewing for. Interview style, you need to understand company's expectations and add to it. Refreshing key contacts, you need to create cheat sheets for the company that you're interviewing at. Reduce uncertainty, you need to plan your logistics. Medically. Contingency plans, you need to, like, think through, hey. What are the types of things that go wrong in interviews? What am I gonna do if that goes wrong? If you knew that, you wouldn't panic. Okay. That's how you, like, radio's interview day variance. And then you need to bring your best self day. There are, like, two aspects of doing that. One is your mental fitness. The other is discipline. And we're gonna, like, talk about mental fitness. Where you have to, like, shed the baggage from your past failures. And that's what we're gonna talk about at the very end. I'm not gonna actually do that. And discipline. You have to bring your best self every day. How you practice how you're gonna show up in interviews. Again, it true for sports. It's true for interviews and work. So when you do practice, don't half ass it. Give it your % best on that particular day. Push yourself every time you show up to practice. Because that's exactly how you're going to show up in an interview. Okay. And that's what I try to force people do when I'm actually doing my boot camp. Just do your best every single day because that's exactly how you're gonna show up in So Cool? So with all of this, do you actually, like, prepare in some form? You still skill stack. You start by actually focusing on product thinking. Spend a lot of time on product thinking because analytical thinking is actually dependent on having good product thinking. You actually take a bunch of products, develop industry knowledge, do deep writing to improve your clarity of thought, try to compress it and do speed writing. And then you actually, like, start working on verbal skills collaborating and putting it all together. And then once you actually, like, done enough product thinking, start letting in analytical thinking for those same products, and actually, like, doing the same thing about them, For leadership, build your story portfolio. Write your stories, and then you start actually, like, speed writing your stories, and then you start verbally doing it. Same thing with x f and partnerships. Mental fitness, discipline should be a daily thing. Resilience and mindset, you need to work on getting rid of all the baggage that you have And then job search, you have to, like, build your career north star, arcs, resume variants, create company list, do inbound, outbound plans, then do a lightweight strategy. You wanna, like, skill stack all of these things, to actually prepare well. Like, a three month period to actually get to a place where you're clearly up leveled your baseline skills and actually, like, you're trying to actually get better at. Okay. This is what I would recommend people do. This is what I would do in some form. Okay. And I'm just gonna use, like, my boot camp plan as actually, like, an example of how you can go about doing it. It's actually, like, available allow on Maven, you can actually look at that. But the plan that I do for the boot camp is roughly this. For people. Actually start with product thinking, do deep deep writing, speed writing, and actually do that. And then doing it across a wide variety of prop products. So I just want you to, like, think about how that is structured. Okay? So you need to, like, have some core framework and then you need to actually do a wide spectrum of product thinking in some form. Like, I over here, I'm saying, hey. Productivity apps, search apps, media apps, marketplaces, ecommerce, generally, where I think business ads, financial products. So it's like a spectrum of products. And actually, like, you can do writing on for each of these things. Okay. You can create your own version of this. Okay. You can create your own plan like this and then do it at home. We just do it. And then you can actually, like, do speed writing practices. Where you've done some deep writing. Now actually, like, you can do fast thirty minute exercise on these things. Then layer in analytical thinking, have some core frameworks that you're gonna use wherever you pick them from, and then actually, like, do practice on top of that. Later in leadership, identifying your stories, and then actually, like, trying to do practice on both, like, leadership things and analytical thinking. And then laid in verbal practice. So you've done writing practice. Now actually, like, start laying in verbal practice. Okay. Do it for leadership. Do it for product thinking. Do it for analytical thinking. Okay. You can yep. You can do these things. So this is roughly, like, what you can do on your own at home. Okay. Just, go look at the Maven thing, and, actually, you can see the list of of single session that is there. It kind of maps to something like this. Starting with product thinking, doing deep product thinking, speed thinking, communication, and all of that together. And then learning analytical thinking, leadership, and XFN. So create your own, like, two month plan like this. Okay. So you wanna do it on your own? Just create a two month plan like this. Take 15 products, and do deep thinking for them. Do speed thinking for them, lay it in analytical for those sets of products, add in, like, leadership and accept it, and create, like, your own sixty day plan. Okay? And if you do that, and if you everyday shop, for two hours on your own, and put in the work it's gonna significantly change how you show up in interviews. Okay. So that's how you prepare well for interviews. So much time do you put in? It's only up to you. If you actually, like, don't have a job right now, and the only thing you're doing is actually, like, trying to get better for interviews. Spend four four hours preparing. And other four hours spend doing something else. Do some skill development. Just preparing for interviews is just mind numbingly painful. Okay? Spend half the day preparing for interviews, spend half the day developing some some skills. Take some courses. Take some AI courses. Take some technology courses. Whatever interests you. Go to market courses. Whatever actually, like, is interesting to you. Okay. So that's what I would say. So if you wanna prepare, just create a sixty day plan for yourself. That has some semblance of this. For yourself. And that's gonna, like, significantly improve your interview preparation. Cool? So it is nine zero three. So I'm gonna stop over here. And we are gonna take a five minute break. Okay. So I wanna catch back up on time. So we're gonna take a five minute break. It is let's say it's 09:05. Let's start at 09:10. Rec Recording stopped.  
Me: It's  
Them: We talked about how to prepare for interviews. Let's talk about each of these of interviews and then actually, like, what, how we can prepare for them, what is good in some form. I tried to compress a lot of what I teach into fifty minutes sessions. I'm not sure how much I I'll get through, so let's actually, like, see. Where this goes. So let's talk about what product thinking is. And then take it from there. So here's my definition. You wanna you have to take an ambiguous market and then create a set of compelling product solutions, and that's what product thinking is. And you do that by solving high value user or business problems, that lead to successful business outcomes. Okay? That's fundamentally, like, what product thinking is. Given an ambiguous market, have to come up with compelling product solutions, and then you do that by solving high value user problems and you should get to successful business outcomes. That's what product thinking is for me. And what makes a product compelling to build? It really needs to be a large market opportunity It should solve high value customer problems. Cost for customers who are willing to pay for it, in some way. And then you need to have clearly differentiated solutions and it should be profitable for the company to actually, like, build that solution. And you need to be able to compete and then win in that market. That's what makes a product compelling to build. And if you have to come up with products that are compelling to build, you need to do some amount of rigorous thinking. And that rigorous thinking starts with trying to understand what is the context of the market and what is the motivation for that company. What is the right target audience to build for? What are the right problems users that are worth building or worth solving? And then what are the creative solutions for for those problems. And doing that part of it is what leads to identifying good products that are worth billing. So it's not about the process, but it's actually when you do that, you end up with products. Or you have a higher likelihood of ending up with compelling products. So let's talk about each of these things. What does context and motivation actually mean? At any point in history, at any point in history, there are opportunities for creating value and there are risks for destroying value. At any point in any market, let's say that you take search a market right now, there are a lot of new value creation opportunities for different companies and there are a lot of risks for destroying value. Some companies who are already actually leading in search. And then there are certain set of dynamics at play based on who can actually capture the value in the market. Some companies already have a lot of power the market that allows them to capture mark value And then other companies have different types of powers that help them actually, like, compete or capture value. Okay. So there's always, like, that in play. And what determines the value creation and value destruction risks? The consumer mindset shifts that are happening at any in time, the technology shifts that are happening at any point in time, the regulatory changes that are happening at any point in time, determines what the value creation opportunities are and value risks are going to be. So for example, language models are the technology shift that's going to create opportunities for new types of answer engines and creates opportunities for some set of companies and then actually going to put Google search business at risk. Unless until they navigate it well. Image generation models for example, are actually going to opportunities for people to create images on the fly and build new business off of that, and actually put at risk general image search. Okay. So every technology shift creates value creation opportunities for and also creates value destruction risk with existing incumbents. And that's something that you have to understand. Similarly, consumer mindset shifts are also going to create value creation opportunities and value destruction risk. I'm gonna give you an example of Ozempic. As an example. Consumers accepting Ozempic as a legitimate way to lose weight is a consumer mindset shift. And what are the implications of that? Pharmaceutical companies value creation opportunities. Hims and Hers value creation opportunities to sell Ozempic to everybody. Value destruction risk, Weight Watchers is going bankrupt. Okay. Simple consumer mindset shift. That's leading to value creation opportunities and value destruction risk. Regulatory risks. Or regulatory changes. Marijuana becoming legal created a bunch of VC funded weed businesses. Value destruction risks, street side vendors for wheat, have lost their businesses. Okay. So at any point in time, there are value creation opportunities and value destruction risks and they're completely dependent on technology changes, consumer mindset shifts, regulatory changes that are happening. And unless you understand that, you can't actually come up with good to build. Okay. That's the first part of understanding market context. The second part of market context is, yes, all of these changes are happening. But who is gonna capture those that value? Okay. Great. Change is happening in search. Can't Satish Murali running a one person company go and actually capture that? Probably not. Why? Because there are powers at play. And you have to, like, understand what the power structures are, and actually, like, who has different powers and what are they gonna use those for So OpenAI is competing with Google in some form effectively. Okay. So they're using one type of power against Google's other types of powers, and they're trying to actually compete that. And that's what value capture dynamics are. And based on which company you work for, you need to figure out actually what your powers are and how do you actually compete against other companies powers. And then you need to truly understand what is the motivation for your to actually, like, innovate this particular market and in through what angle. That's what context and motivation is. If you don't go deep into con market contacts market dynamics and understand that deeply, it's gonna be really hard to actually come up with good products to build. Okay. That's the first step. Of actually, like, doing this. Then the second thing is about target audience. And what's it about? The outcome is that which customers valuable to focus on in this particular market And what high value customers my company positioned to serve and win? And then who which partners do I need actually, like, serve those customers well? Okay. So the fundamental things over here is that what is native segmentation for this particular market? In this market, in this for this product space, how do I segment the entire set of people? And why? Like, how is it native to that? And you have to, like, understand that. And the reason to do segmentation because you want to identify groups of people who have similar problems so that you can build much more compelling prob solutions for them. So when you segment, the goal is to make sure that the different groups of have different problems. So that you can build differentiated solutions for them. That's what native segmentation is. And then the next thing is that which of these segments high willingness to pay? And I'm gonna actually, like, pay for the products that that are gonna be built in that space. Then the next question is, which of these high value segments can I compete and win? Okay. Maybe there is actually, like, a group of CPOs for whom there's some who might actually be willing to pay a lot of money for something. And there are some pain points that are worth solving for them. But am I the right person to actually, like, build for that? Okay. That's the set of things to think through when you're actually thinking about target audience. How do I do segmentation in this space? Which segments I have high willingness to pay? Which segments can I compete and win for, and then what partners do I need to actually, like, serve this customer set bet well? Okay. That's what what target finding the right target audience is about. And then you wanna figure out which problems are worth solving and how do you figure out them? What are the problems that are actually important and urgent for the target customers? That they have high willingness to pay? And then what sequence should you solve those problems in so that you can actually keep capturing value as you go along? And then you wanna actually come up with creative solutions that solve the problem. If somebody has a problem, how do you actually solve that in a deep way that they are willing to pay for And how do you leverage technology and humans to provide high quality solutions? And then which solutions you prioritize and in what sequence? Hey. Should I be building a high quality course for interview prep, or should I just actually, like, build an AI agent people to do mock interview practice? That's actually, like, what this is about. What solutions are worth and in what order. In what order? Okay. So Okay. So if you do that, if you truly understand context and motivation, you understand what the opportunities are, what the risks are, who has power to capture value, what is your company's motivation, and how do you go about doing it. You need to understand who are the customers that are valuable in this market, who willing to pay, and you can compete and win. Then you should prioritize What problems are actually, like, important and urgent that people are willing to pay for, and what sequence you wanna tackle them in, And actually, what is a great experience for people? If you solve that problem? And how do you, like, leverage technology and humans to solve it? What solutions you're building in what sequence. If you do that work, then you actually, like, have a higher probability of ending up with compelling products you build. So that's what So that's what product thinking is. So how does product thinking work in work at work versus interviews? My philosophy is that you're doing the exact same work but in shorter periods of time and you're doing the subset of it in interviews. Okay? So I'm gonna talk about how that works. So let's say that you're doing product thinking or product strategy, whatever you wanna call it, for work. You probably do it in, four to eight week cycles. And you have a bunch of inputs. The inputs are that, and then you're working with a group of people. You might have, like, market researchers, like data scientists, user researchers, You have a design team that you're working with, an engineering team that you're working with as a PM. And there's a bunch of inputs that come in, like, somebody's giving you market research, Intel data that you might have, primary user research, You do some design sprints, you do some prototype testing. There's a bunch of inputs that are that are actually, like, going into the process. And you're doing four to six weeks of work with a group of people. You're going through the same exact process. In some form. Put together, like, a brief of actually, like, what the market context is and some segmentation, You validate your segments in some form by actually, like, doing user research. You identify problems. You're prioritizing them. You're actually coming with solutions. And you're actually doing prototype testing. If you're doing interview preparation for a specific company, let's say that actually you want a job at Uber, You can spend, like, twenty hours preparing for it, and you're doing it alone or you can actually, like, partner with some friends to actually, like, do preparation. Again, like, you are doing all of this work on your own. You have primary research. Market research. If you wanted to do, you can find market research online. A bunch of different ways. You can actually, like, get feedback from your partners and all of these things. And you can brainstorm. And you actually do this work, and you spend can spend twenty hours doing this work. With the limited amount of public knowledge that you have. In an interview, doing the exact same thing, but you're doing it in thirty minutes. And you're doing it with whatever is in your brain. And what the interviewer is willing to give you. You can ask interviewer some questions. They can give you some initial input. But 99% of the stuff is coming from what is in your brain. Actually, like, little bit of interviewer input, and you're doing the exact same work. And then if you are doing it for work, you're actually, like, going to explore the full tree. You're actually going to take all of the segments that matter, For each of the segments, you're gonna identify a bunch of problems that are worth solving. And for each of the problems, you might actually, like, have a bunch of solution and you have a full tree. And then once you have the full tree, prioritize within that and then say, hey. We are gonna focus on only these two segments. Wanna focus on only these two problems for this segment. We're actually going to focus on just these solutions. For this other segment, we're gonna, like, focus on these two problems, and we're gonna focus on these two solutions and this becomes your road map. In some form. This is what you would do at work. You have the full tree, and then you prioritize within the tree. And when you're doing it at an interview, sequential prioritization. You identify segments and then you choose one segment and ignore the other segments. Other segments are dead to you at that point in time. Once you've made a sec segmentation choice, you ignore the other segments, and you just focus on that one segment. And then you identify a bunch of problems. And then you choose one problem. And then the other problems are dead to you. You take that one problem and then figure out the solutions are for that. And then you pick one solution and you just go deep in that. So that's the delta for me between actually how you do product thinking in an interview versus you're doing it for work. At work, you can explore the full tree. You can go back and forth between them. Based on the problems, you can actually, like, refactor segments again if you wanted to. You build out your full tree and then you prioritize within that. Okay. And then doing an interview, you're doing sequential prioritization. You prioritize a segment, one segment. You prioritize problems, one problem. You prioritize solutions, one solution. Then you expand that out. Okay. Starts a delta between doing product thinking in an interview versus product thinking in real life. So what I would actually tell you, the thing to take away from this is that people think interviews are a game. And they should actually, like, game the system somehow. What does the interviewer want? That's what people are trying to think about. Instead, think about if I was a PM at this company, what would I build? If that was my job, what would I actually build? That's what you're trying to do in interview. Okay? Then the next thing that I wanna touch on is what is product thinking at different levels? The common question that people ask me is, hey. Like, become an l seven or an l eight or a l 10 at the company. How do I show that I'm operating at that level? That's a common question that I get from people. So what does product thinking mean different levels or different altitudes? So the way to think about it is, there's complexity of problems that you're actually capable of tackling. And if you think about the lowest level of product thinking, it's about an action level. How do you like, get people to sign up for something or how do you how do you get people to change a photo? Of their profile? At the action level. Then there's, like, a level above that, which is like a subtask level, a task level, a level, a product group level, a company level. Again, don't focus on the ex exact that I'm saying, but it's a relativeness of it that I want you to think about. There's, a lower level lowest level thing, which is, like, some specific feature thing, and the super highest level is a company or industry level. Thinking of problems. Okay. And that determines, like, the attitude of somebody's product thinking and the level at which actually, like, they should be at in a company. So let's say let's say we take dating. Let's talk about problems at different altitudes and ambiguity for dating. The lowest level think it could be that how do you improve photo selection flow on Tinder? You are setting up your profile, your app, you are putting up uploading a photo. How do you actually, like, get that to be better? Or the next level could be, how do you improve the profile page for somebody? The next level up is, how do you improve the entire onboarding flow? The next level up could be how do you improve matching on Tinder? Next level up could be how do you serve women better on Tinder. The next level up is, hey, dating is completely screwed up. In the world. How do we fix dating? That's thinking of the industry or company level. There are different altitudes of product problems that somebody is able to, like, tackle. And, like, here is, like, my rough thing. Right? So usually, everybody, when they start off in PM carriers, like, you start off at the APM, RPM level. Doing action level, subtask level things. You're, like, four or five. You're doing task level things. Five or six, you're doing team level things. Like, product group level things at at, like, seven, eight, like, m two d one, and then company level IC nine. All these are using Fang level things. So for example, an m two or a d one at at, like, Meta would actually be like a VP at Oracle or VP at DoorDash, for example. In some form. So it's always like a mapping between bang levels and actually, like, other companies, from just a scale perspective. Like, most VPs people who are at VPs at a lot of com well known companies would come in at, like, director level in in, like, a fine company. Example. Okay. So just, like, giving examples of what the relative altitudes are the fundamental thing that I want people to to think about is what level of problem can you start with and then end up with the product solution in a thirty minute interview? That's what you should aim for. So people ask me the next question people ask me is, hey. What altitude of problem should I be like, talking about in interviews? And my response to that is, talk about the attitude of problems that you can land well in a thirty minute interview. Okay. When I I was interviewing for jobs in 2011, I don't think I could have actually, like, taken an industry level problem and actually, like, landed it well. In some form. Now I can do that. Now I can actually, like, start with, hey. Like, how do you change dating in the world? I can start there and I can actually, like, say, okay. Here's a specific product I'm gonna build. And I can do that today. So you figure out what is the attitude of problem that you can tackle in a thirty minute interview. And sometimes it is very different for a for based on what industry you knowledge in, you've thought about before. So that's the thing to actually play around with. Somebody asked Somebody asked why do people ask company level questions for entry level PM role? They I'm not asking company level questions. In most so, again, if you are looking for comp jobs at Meta or Google or any of these companies, they're actually there is an RPM program. And there's a PM program. PM programs are expecting people to have, like, six to ten years of of PM experience before they actually, like, hire people. As an IC five or a six. So at that level, you should be able to, like, think about higher order problems. Okay? And so people are even when ask an open ended question, you can answer the question at different altitudes. Hey, what product would you build Facebook groups? A junior p person is actually gonna talk about some onboarding flow or along those lines that they're interested in or actually what is the admin experience? And, like, a VP level person might actually think about hey. How do we think about communities very differently? The same question can I have answers at different attitudes? So I wanna, like, give an example response I'm gonna talk about a few key things to take away with respect to how you do product thinking well in interviews. So let's say we take an example of marketplaces and real estate for example, and then say, okay. Hey, Redfin. You're a PM at Redfin. What would you build and why? Let's say that's the question that you have. Like a small set of market context that I could talk about, which is, hey. There's some consumer trends, which is finding a house that you like and fits in your budget, is a soul sucking experience. High interest rates, market seems to have cooled off just a little bit, private equity firms are buying up single family homes and apartment complexes, Return to work like, is pushing people to, like, rebuy homes again. Real estate, 6% commission has been whited. Can be negotiated now, and then that might actually, like, have some impact on Redfin in some form. And then there's some technology changes, AR, VR, headsets are getting cheaper and better. Like, AI technology for image and scene matching and scene generation is actually, like, going to have an impact on what product experiences you could be building. And there's, like, some competitive dynamics of play. So let's say there's, like, some amount of high level contacts over here. And then what is the motivation for Redfin? Like, really says, commissions used be, like, a differentiator for Redfin. And if actually, like, that cuts into value proposition, what should they be actually, like, focusing on as their value proposition to differentiate from other places? Housing market will get fragmented with private equity purchases. So how should they be thinking about that? And then AI will redefine the user experience for buying and selling houses in different ways. So if Redfin needs to actually, like, get need need to get ahead of these shifts, that are coming on. So what should the product mission be? Make real estate buying and more consumer friendly. Okay. Starts the motivation for Redfin. And then I'm just gonna focus there are, like, both the the buyers and the seller side of it. And I'm making a choice in this particular example to focus buyer experience, and I'm doing segmentation for the buyers. And if I wanna do segmentation for the buyers, what are the factors that I'm gonna use to do segmentation Like, the top three factors for me are use case. Are people buying it as a primary home, or are they buying it for investment? Lifestage, are they a first time home buyer, or are they a repeat home buyer? Lifestage or kids, are they expanding or contracting? Okay. Those are the factors that matter. In whether people have similar problems or different problems. So for example, if people are buying a home as for a primary home, they have very different problems than if people are buying it as an investment property. If people are first time home buyer, they have very different problems than if they're a repeat home buyer. They've already bought a home. And if they're expanding, they might have one set of problems. If they're contracting, they might have a different set of problems. Okay. Those are top three factors for me. Again, this is my segmentation. Top three factors. I have these factors, then how do I do segments based on these? So I'm gonna, like, end up with four segments. I'm gonna talk to you later about how I did the segmentation. Okay? So I'm ending up with four segments over here. My four segments are first time homebuyers, which are, like, younger people looking to stop renting, have lower budgets, and down payment money, don't know what their real needs are with the house, don't understand what the home buying process is. Yeah. That's what first time home buyers are. Families who are upsizing. Like, families who are becoming more affluent may have kids, have more budget, can put more down payment, have a clearer mental model of what they want from their next house, They understand what the home buying process is, and they know specific help that they need. That's what families were upsizing on. And then there's casual real estate investors. They have, like, extra savings that they wanna invest. They they may be open to locations across the country so that they fit into their budget. And they may not be as knowledgeable about the investment market They potentially need help with actually managing the rent real estate portfolio. And then there's, like, seniors who are downsizing. And kids are out of the house, and they don't need a large house. They need to reinvest their real real estate money into other liquid assets. And use it for other purposes. Some people may wanna stay in the same place, other people wanna relocate to a cheaper area. Okay. So I'm like, had four segments of mine. They're not, like, perfectly missy, but they're approximately missy. In my perspective. And then Like, I'm picking one segment, and I'm actually, like, to choice, I'm gonna use casual real estate agents. And like, I'm gonna choose some high level problems for casual real estate investors. Okay? What I'm gonna start by thinking about what are the higher order jobs. That people want to do with a platform like Redfin they're casual real estate investors. I wanna, like, differentiate between what jobs are and what problems are. Jobs are what people are trying to accomplish. Problems are what gets in the way of them accomplishing those jobs. That's the delta that I want you all to, like, think about. And what are the higher order jobs if somebody wants to be a casual real estate investors? They need to set some goals on how much to invest, what geography constraints, what ROI they're expecting. They need some research tools. On on actually, like, how to find the geographies to invest in, what type of real estate, what the pricing is, and all these things. They might need some partnerships because they can actually go check them out. They They might need some real estate agents in different places. They need some real estate group to manage. Things after they bought them. They might need some deal flow tools. They need, like, inform new deals coming through. And for them to manage a pipeline. They might need some transaction support, due diligence financing, closing support, and all of that. And they might need post transaction support for property management, reselling, and those kinds of things. Those are the higher order jobs. If I am a casual real estate investors, I need to be doing these things to be successful. These are not problems. These are actually, like, what I need to do. Now what are the product problems people might be having? Are the most intense ones? And I'm actually, like, showing three things that I think are are are the more important and urgent problems. The first one is doing research. To actually figure out, hey. What should I be buying in some form? Some form of goal setting and advice on actually how should I be thinking on a real estate portfolio. And then actually, like, some amount of deal flow tools and support. Okay. Those are, like, what I think are high level problems. Again, like, you can go 10 x deeper into why each of these things is. But I'm trying to, like, fit everything into a fifteen minute session. So then I'm prioritizing one problem over here, and I'm prioritizing the problem of research. I'm taking that problem, and I'm expanding it up. The problem for research is I have money to reinvest in real estate, but I don't know what to buy. That's actually, like, what the one line version of the problem is. And if you have to come up with good solutions, you need to actually expand the problem and go much deeper into it. And what does this one line problem actually mean? It means which geographies perform well in real estate investment what level of investment do I need for different geographies, What type of real estate is good for investment in different geographies? What does typical ROI look like for geography and real estate pairs? What are anomalies in the geography? What drives growth in a specific geography? What are the risks associated with the geography? What is the economic outlook for the geography? What is the renting versus buying trends in that particular geography? What is the inventory trends in that geography? Like, what are the different types of real estate investment vehicles that I might have? These are, like, some of the details of that line problem that I had, which is I have money to invest in real estate, but I don't know what to buy. Okay. I'm expanding all this problem. And then, like, you have to figure out, okay, what are the solutions that I could actually be be building? I can, like, partner with some other company and integrate their product into my product if it exists? I can license data and then build a product on top of that. I can create my own dataset and then actually, like, build a full product. I can actually, like, buy some company that already does this stuff. Okay. Those are all, like, options for what I could do to solve this problem. And let's say that I say, I'm gonna create my own data and actually build a full product. For some reason, I'm, like, doing that. Then this is the problem that I have. And I can actually build a solution that fully solves that thing. I'm gonna build a real estate investment tool for casual investors. And it's gonna have three types of features a geography analysis tool, a housing type analysis tool, investment portfolio tool. And the geography tool is gonna tell me like, tools evaluate real estate by city, the economic drivers of it, and the risk for each city. The trends and abnormalities for that market. The housing type analysis is gonna show what is the housing mix in a geography, the price differences by house type in a geography, returns by housing type for investments over different time periods, investment trends by like, inventory trends by housing type. And then investment portfolio is gonna say, okay. What is the level of investment by market that you need? Mix of any given investment amount, types of investment, vehicles that are available, loan types, tax implications, and those types of things. K. So I have a problem. I have, like, depth of the problem, and I have depth of solution. Okay. That's what actually, like, is a very good interview response. In my first back. I could even, like, take a different segment and say, okay. Hey. Homebuyers, I'm gonna actually, like, solve for them in some form. And I can actually, like, pick what is the higher order jobs, what are the high level problems. I can find a problem for them. And I can actually, like, expand the problem, come up with some high level solutions. And, actually, like, I can build a solution for different segment. So there is no there's no one response that actually, like, is great, but there's a set of responses that could be really good. You can take some good segments. You can take any one of the segments, come with a good problem and a good solution, that is compelling to build. Because a company has a portfolio in a road map eventually. And you could pick any one of those really good problems and solution segment problem solution pairs actually, like, do a pretty good job in an interview. Okay. So again, like, I'm gonna with Reddit, I did gonna show a similar thing where example, here, I could come up with, like, five segments. I can have problems for all of the segments. I can do solutions for all of them. If I was doing at home, practice, twenty hours or eight hours or four hours if I'm doing, I can do a full tree like this. For, like, for any of the companies that I'm interviewing at. And if I do this in a thirty minute, I can actually, like, do go down one path and actually do a pretty good solution for that. So I'm gonna talk about a few key things. I I about that matter in in in in these things. So I'm gonna skip. Yeah. So segmentation. I wanna talk about segmentation because people struggle with segmentation. It's, like, a couple of things that I want you all to, like, think about. You can do segmentation in different levels of complexity. You can do super simple single segmentation. Let's say that I'm taking this reference example. And I can actually, like, just I've taken my factors that determine whether whether people have different problems or not. And I came up with three three factors. I can take just one factor, and then do single factor segmentation. So for example, I can say, I'm gonna do just use case based segmentation. Primary home versus investment home. And I can have just two segments. And each of these segments has very different problems and I can build different solutions for them. And that actually could be a decent place to land. You could do two factor segmentation where you can now layer in life stage, which is first time buyers, versus repeat home buyers. And if you wanna do two factor segmentation, you've actually, like, started with this single factor segmentation of primary home buyers, versus casual real estate investors, You layer in the second factor, which is first time buyers versus repeat buyers, and see which segments do you need to break into further segments. So primary home buyers I can break it down again by first time home buyers versus repeat home buyers. So I can take primary homebuyers, break it up into two, and then say, first time home buyers, repeat home buyers. But casual real estate investors usually already own a home, so there is only repeat home buyers who are usually casual real estate investors. So there's no need to actually, like, break up that segment again. So I've taken primary home buyers and broken the number up into two segments. But I'm just, leaving casual investor in real estate investors as it is. I end up with three segments. Then now if I wanna do three factor segmentation, I can layer in this third factor, which is life stage or kids. Expanding or contracting. And then now I can actually, like, say, okay. Hey. Which segments do I need to break down? A first time home buyers, a repeat home buyers, and I'm, like, casual real estate investors. First time home buyers, does not matter whether they're expanding or contracting. They don't have a house, they need to buy a house. I'm not gonna split that up based on life stage expanding versus contracting. Repeat home buyers, they already have a home. Now expanding versus contracting matters. So I'm gonna split them up into two, and I'm gonna, like, name one families who are upsizing, and the other one seniors who are downsizing. And then casually listed as expanding contracting does not matter for that particular segment. I'm gonna leave that as it is. Good call. Three factor. Yep. So that's how I did my segmentation. I first took what are the factors, stack rank them, And then I'm actually like, how what factors will layer it. And I ended up with, like, four segments by using three factors.  
Me: It's bad  
Them: And they are approximately MECE. Segmentation is never actually gonna be fully MECE. But what you're aiming for is approximately MEC. There's gonna be, like, some amount of overlap between the segments, but but it's mostly, like, it's approximately, missy, based on the need for for that particular product type. K. Single factor segmentation, just primary home buyers, casual real estate investors. Two factor segmentation, first time home buyers, repeat home buyers, casual real estate investors. Three factor segmentation, first time home buyers, families who are upsizing. Seniors who are downsizing, and casual real estate investors. Okay? So in an interview, you wanna end up with like, three to five seg segments. For it to actually look compelling. And then you might wanna, like, layer in Sometimes just one factor is actually, like, good enough. When the factor has, like, divides a lot. And then maybe two is good enough at that point. And in some cases, you might actually, like, need three factors. And that's totally fine. You need to know what you need and what level of complexity you can actually, like, handle an interview. And then with respect to identifying problems, there's, like, a couple of ways to do with this, but here is, like, one approach. The approach that I showed you in interviews is that first show deep user empathy. And what I mean by deep user empathy is to actually, like, paint a vivid picture of what that person is in your mind. So for example, casual real estate investors, have extra savings they want to invest They're open to locations across the company that fit their budget. May not be as knowledgeable about the investment market, They need like, about a portfolio in some form. That actually, like, paints a picture of someone. It's somebody like me. Okay. I have extra savings, cash lying around, and but I'm, like, don't have enough knowledge to actually, like, go invest in real estate, so I'm not doing it. So I might want some help with knowledge. And, actually, like, I'm open to locations I don't think I can buy like, a second property in in the Bay Area, but maybe I can buy it in, like, Arizona. As an investment property. And need to probably if I'm gonna go into real estate, then I might think of I need it to be a portfolio for it to make sense Otherwise, I can just, put money in the stock market. Sounds like creating empathy for the user. And then actually thinking about what their jobs are and then from that, going into what the high level problems are. Okay. So that's the way to actually, like, identify problems that are worth solving. Deep user empathy, higher order jobs, what are the problems in actually, like, accomplishing those jobs? And then identifying solutions The fundamental mistake that people make they try to go from a one line definition of a problem to a solution. But if you want to do really good solutions, you need to expand the problem. If I had to come up with solutions based on just this one line problem, I have money to invest in real estate, but I don't know what to buy. I my solutions would suck. But I've expanded up the problem so much now I can actually, like, figure out what a really good solution is. And does it actually solve the problem? And it creates clarity on what is the actual problem. A lot of times, like, somebody send an email saying, hey. Like, I got feedback that I didn't have good solutions. Or my solution was not solving the problem. And then the high likelihood that the person did not expand out the problem And if they didn't expand the problem, there's a high likelihood that they would have come up with some solution that does not actually solve the problem. So expand the problem. And then go try to solve it. It gets you clarity on what is the actual problem. That you're trying to solve. And then, like, in between, come up with high other multiple solutions. I I'm using this, like, high level directions, but it's, like, options. If you can actually, like, call this solution options if you want. Okay. So that's what I wanted you all to, like, take away with respect to like, a few key things. How Market context, there's a bunch of in information that you can actually get on the Internet. Every comp I I didn't actually, like, have a slide for this. But I wanna, like, talk about context and motivation for a second. If you want actually, like, context and motivation for a particular company, again, just maybe, like let me just take thirty seconds for a sec. Just gonna pull a slide for from someplace. Else. So, like, a couple of questions that people have with respect to context and motivation that they typically ask me. So I'm gonna just actually, like, add that over here. So the first question that people ask is, is how do I get information to understand com context? So the first thing that you also be doing is that there's a lot of public filings for public companies. Founders write letters, do interviews. There are company conferences that have a lot of videos. Company websites explain all of the products. There are blogs help centers explain what the nuance of the products are. There's traffic data that you can actually look up. There's other writers who write about different products. Market research report reports. You can actually ask ChatGPT in Perplexity. Information and actually, like, it'll give you So you can get a lot of context information from publicly available sources. If you invest the time in doing that. Okay. That's, like, the first question. Where do I get information from? Here are actually, like, all of the things that matter. Then the second thing that people ask is, There's just a lot of information. What is the thing that I should be talking about from a context about in an interview? Could spend thirty minutes just talking about context. So what is the context that truly matters in an interview? So when I'm actually, like, doing the twenty hour version of something, I'm gonna write a one page thing about context. But in an interview, I need to have just bullet points or four bullet points about context. So what are those things that they those three or four bullet points of context? The question to ask is, what technology trends or consumer trends or regulations are going to create value creation opportunities value destruction risks and how in the product. That's the question to answer. And if you do that, you get specific about the technology how it's gonna have an impact on Okay. So for example, the way to say any of those bullet points is language models, can actually answer a lot of questions And as a result, I'm gonna change what search experiences look like. Image models can generate what people need on the fly and can actually, like, replace stock photography. That's the level of detail you need to get to with respect to context and you have to, like, answer that. And if you put that filter on, you can actually come up with, like, two or three bullet points that truly matter. Okay. Start about contacts. Talked about segmentation. I talked about problems and solutions. And I'm gonna, like, close it again. Hey. Deliberate practice. How do you improve your product thinking? Industry knowledge, read and listen a lot. Clarity of thought, deep writing, like, take a problem and then actually, like, spend four hours writing, the answer to that. Speed thinking, do it in, like, thirty minutes. Communication, presence, collaboration, and all of these things. That's how you actually, like, do it. And like, in the interview boot camp, I tried to actually, like, bootstrap this for people where for, like, a bunch of teams, I gave a bunch of that actually provides a baseline knowledge that people can then double down on. And then with respect to templates, I want you to, like, create, like, a like, a twenty hour template, a one hour template, and thirty minute template. I have, like, a few of those that I use. Where if it's, a twenty hour template, I have, like, a longer version of it that that actually, like, I would write then if it's, a thirty minute template, you wanna, like, get super crisp, write in short bullet points, have a shorter version of it. That's what I I would ask you to do to improve your product thinking. Take, like, 10, 15 products. And go through this process, and it'll transform what you do. Cool? So it is nine fifty eight So I wanna stay on track with respect to time. This was helpful with respect to product thinking. We are going to start analytical thinking in a little bit. Let me just actually do a couple of things. Recording stopped. I'm gonna I'm gonna just put a time. Starts at 10:05 Pacific time. Good. So we're start analytical thinking at 10:05 Pacific time. Opportunities. Are we gonna, like, debug product issues based on metrics trends? Then we make some product and metrics trade offs. Then we do some product simulation. Is anybody having problems with getting kicked out of the Zoom or any of those? Just let me know. Wanna see if it's, any broader issue versus not. So just let me know if, yes, if there's a problem. Yep. Cool. Yeah. So this of these these things I think prioritizing opportunities like, I showed showed you, like, examples of of the types of questions that people have. I'm gonna talk about a few things over here. I can't, like, cover everything. Probably gonna take a lot of time, but I just wanna touch on a few few types of things that, people don't normally understand well. So one, I I just want you to understand that there's different types of questions. I I just feel that that I'm not seeing a good articulation of what are the types of questions that are asked in analytical thinking interviews, and then this is what I think is is is right way to think about it. Goal setting and choosing metrics, I think that that that's everybody knows about that. Priorizing opportunities, these are the estimation type questions I don't think people are them as much anymore. Luce Lynn does a good job of that, so I'm not gonna like, touch on on estimation in some form. Think, fundamentally, people don't understand the other types of questions. The people just say, okay. Trade off questions is what people call them, but, really, they're few types of questions out of there. Debugging, product issues based on metrics. And then actually, like, trade offs between different types of products and metrics in some form. Something is going up, something is going down. What would you do? And then there's product simulation. Would you choose this versus that as a product experience? Those are different types of questions. And I'm gonna touch on a couple of these because only limited amount of time. So spend some time on actually setting goals and choosing metrics. There's just some huge misconception about how to go about doing this. So I'm gonna share my perspective on this. Again, what would you do if you were the PM for that product? That's fundamentally what you're trying to actually do over So I'm gonna start by talking about metrics at a macro level. Okay? So how do you think about metrics in general? And then how do you answer this question of, are the PM for a particular product. What would you set as a north star goal, and how would you what metrics would you use to measure success? I wanna, like, talk through that piece of it for you all. So if you, like, think about core metrics, I wanna explain a couple of things. One is if you have a product and then I'm gonna assume that the product has both the customer side and a and a partner side of it. So I think I need to, like, introduce this concept of customer versus partner. So let's say that you are Uber. You have riders and drivers. Okay. If you are DoorDash, you have who are face placing food orders, and then you have restaurants,  
Me: That's what?  
Them: then you have delivery workers. You are Instacart. You have the people who are placing the orders. And you have the, grocery chains You have the in store shoppers. And you have the drivers who are delivering. Okay? People view all of these as two sided, three sided, four sided shit, and I don't actually, like, like that. What I try to tell people is there is a customer who's paying for stuff and there is a provider who is the platform plus the partners who are actually, like, delivering that service. In the Uber case, the rider is the customer and Uber plus the driver are delivering that service. And Uber is a platform and the driver is the partner. If you take DoorDash, the person who's paying for the food is the customer. The restaurant and the delivery driver are partners. For DoorDash with a platform. For Instacart, the people who are ordering groceries are the customers, And then grocery chains the in store shoppers, and the delivery drivers are all partners. In some form. The platform which is in cigar. Okay. The mental model that I have. And then if you look at from that perspective, you have customer centric metrics, which are metrics about the customers and you have partner centric metrics. And then you have aggregate metrics about the overall business. That's how I actually, like, look at core metrics for business. If you're talking about a media business, sometimes you might have a partner, sometimes you may not have a partner. So just wanna call them. And then let's go through all different types of metrics for these things. The aggregate metrics could be, like, overall monetization metrics, total consumption metrics, could be competition metrics. Customer centric metrics could be about the customer growth, which is the number of customers you have in some form, customer engagement, the metrics around that, and it or it could be about customer retention. And if you have partner centric metrics, could be a partner growth, partner engagement, and partner retention. And, again, the growth met numbers could be at different stages of funnel if you wanna do that. Okay. So I just wanna, like, set a framework for how to think about core metrics. And then for different product teams, you'll have different metrics that fall in each of these buckets. If I'm doing media products, social media, newspapers, community message messaging like Reddit and all of these things, There's, like, one type of metrics that fall into this. Modernization could be, like, monthly recurring revenue or recurring revenue or ad revenue. Consumption, be like total consumption could be total time spent. Total watch time. These are vanity metrics that YouTube shares. Total content items watched, total content available in the library, how many movies do I have, on Netflix, Like, in some form. Competition could be about market share. Like, primacy. Are you, like, the primary market? For primary user in some form? I'm gonna, like, simplify this and remove this so that people wanna ask me questions about it right now. And then if you think about customer centric metrics, the customer growth metrics could be, like, active people. Like, they active people, weekly active people, monthly active people. And if you have a paid version of it, active paid subscribers in some form, engagement metrics could be time spent per person, or it could be, like, number of media people are watching per person. In some form. Retention could be, like, daily active people by monthly active people. Partner growth, again, active creators, admins, moderators, communities, whatever that is. Like, engagement is post per daily active video per daily active people. And retention is day 30, 60, 90 retention for creators and communities. Or it could be, like, by stage that they have, you can actually cut it across those. So for media type products, you have, like, different metrics that you have that fill in each of these buckets. And then you have, like, quality and task trust metrics for media type products, content quality, personalization quality, community quality, service quality, any of these things. Things. And then for marketplaces, you might have a different set of metrics for each of these buckets. Overall monetization could things could be like gross merchandise value, gross revenue, net revenue, recurring revenue, annual recurring revenue, ads revenue. Consumption is total transactions. Competition would be market share. Okay. So you have different metrics that fall into these buckets. Marketplaces, ecommerce, for productivity, and and all of these things. And, like, you can have, like, a huge thing for each of these types of teams, like media, marketplaces, commerce, messaging, productivity, Internet, like, search, business products, advertising, you can have different metrics that fall into That's a base that I wanna actually, like, start with. Then let's say that somebody asks you a question about, hey. You are a PM for some product. What would you set as a north star metrics met not what would you set as a goal and the not star metric for that particular product? A response might look like something like this. You need to have What is my primary north star metric? What are the secondary metrics I'm actually going to track? Along with it, to know the full picture of the business? And what are the guardrail or counter metrics that I'm gonna use to make sure that I'm not growing in, like, an abuser way? So that's what you need to actually have as a response when somebody asks, hey. You are the PM for Netflix. What metrics would you have? You're a PM for Instagram. What would you have? Okay. So DAP is daily active people. MAP is monthly active people. So I'm just, like, telling you what is the frame of the response that you need if actually, like, people ask you that. And you're gonna if you if you like, do any interviews, you're gonna get a base metrics question. Which could be like, hey. You're a PM at LinkedIn working on jobs product goal would you set for the team, and how would you measure success? You might actually get a question like that, and then how do you answer that? In some form? So the fundamental thing is that when you set a goal, what you're trying to do is find a goal that actually aligned with what is the product's purpose. And then you have to, like, have an English language definition of what success means, and that is what a goal is. Okay. I think people don't understand what is a goal and what is a metric. Start with. At least, like, the the definition of it. A metric a goal is what is the English language definition of success. And a metric is what is the calculable thing that measures that goal. That's what actually, like, it is. Okay. And if you have to, like, set good goals and and have good metrics, You need to start by actually thinking about what is the product in some form, wanna, like, understand what the product is. So for example, in in this LinkedIn jobs, there is, a LinkedIn careers marketplace which is both the job seeker and actually, like, the company side of recruiting side of it. And there are, like, two products inside it. One product is the LinkedIn job product, which is for job seekers. And then there is a second product, which is LinkedIn recruiter product, which is only recruiter facing. And that's a broader marketplace. And this product that we're talking about is just the LinkedIn jobs product. And what does the LinkedIn jobs product do? It allows people to actually discover jobs, apply for jobs, improve their resumes, prepare for interviews, and then and then some amount of posting jobs. Because that's what the LinkedIn jobs product is. And then you wanna, like, understand what the market context is. You have to, like, think through that. And then you have to, like, understand what the motivation for the jobs product is, and they have you have to have a purpose. And the what is the purpose for the jobs product? Connect people with jobs that they're most suited for. And that's the purpose or the mission of actually, like, the LinkedIn jobs product. Okay. So you have to truly understand what is this product trying to solve for before you can set a goal and you can choose metrics for it? Okay. So that's the first place to start. And once you do that, then you can actually say, hey. Hey. What is like, the goal this particular product? And that's English language definition of success. And we are people use LinkedIn as a primary way to find jobs. That's actually, like, what is the English language definition of success or the goal for LinkedIn jobs. And if that is a goal, what should the metric actually capture? It should capture the number of people of people who are looking for jobs and what is the progress towards finding a job because that's what it is, that you're people with jobs that they're most qualified for. Okay. That's what actually, like, you're trying to capture with your metric. So then you can actually, like, go through your metrics options aggregate metrics, job seeker centric metrics, and then job creator metrics. You have, like, all of these types of metrics, and then you're making two fundamental decisions. Are you choosing an aggregate metric or a job seeker metric or a job creator metric? And what depth of funnel are you actually, like, using the metric for the goal metric? And you actually, like, just lay that out what do you want to actually, like, figure out when you're prioritizing a metric. You can choose between any of these metrics. Which one do you choose? You wanna actually, like, see if the metric is capturing the goal that you want to actually, like, measure for. You wanna see if LinkedIn can actually impact that outcome and then is a metric actually measurable? And you actually evaluate that, and then you end up with something. And over here, I based on the way that I'm framing it, in order for the metric to measure the goal, you need to actually like, make sure that you're counting the number of people who are applying for jobs. And actually, like, it should capture some portion of actually, like, our they making progress towards finding a job? I would actually, like, optimize the job seeker metric. And then can LinkedIn impact the outcome? They can impact how many people are applying for jobs. But they can't actually impact how many people are getting jobs. Someone actually, like, pick at the top of the funnel for it, and if it's measurable. So the goal metric that I'm gonna pick is number of people who apply for jobs a quarter or a year. That's the metric that I'm gonna land on as a north star metric. And once you have that, you have to actually figure out What is the definition of that metric? The definition of a metric is the SQL query that somebody would write. Or, like, the code that an engineer would write if they were actually creating a metrics dashboard. So you can't just have, like, a broad thing of number of people who apply for jobs in period of time. You have to talk about how many jobs do they need to apply, in what period of time, for them to actually be counted as who is looking for jobs? On LinkedIn. And that is the discussion that you need to, like, have in the interview and then actually, like, come up with the numbers. So over here, what I'm saying is that, hey. People might need to apply for some x number of jobs. And you have to, like, talk about how you would make that choice. In some wide period of time. So it could be something like, hey. Number of people who apply for five jobs in, like, a month. That is a signal that people are actively looking for jobs on LinkedIn. And that's a definition metric definition that you need to have somebody can go write a query for it. Cool. So then the question is, hey. Like, do we always, like, choose a customer centric side metric Some of these are some examples where if you were actually, like, doing metrics for Facebook stories, then actually the purpose of the product is to help people share and connect over their daily moments. If that's the purpose of the thing, then you wanna capture who is sharing stories. So then would pick a creator centric metric for that. Okay. And then if you were actually, like, doing something like DoorDash, where your primary purpose is to actually grow the local economy, if you're, like, ecommerce in some form where you're actually, like, helping businesses like, small businesses actually, like, directly sell to customers, then you might actually, like, choose an aggregate metric And you might say, okay. Hey. I'm gonna, like, choose number of transactions. Or gross merchandise value. So based on what is the purpose or mission of the company, and the stage of the particular product, you might actually, like, choose between an aggregate metric versus a buyer centric metric versus seller sent metric in some form. Okay. That is a discussion to have in an interview. And then with a north star metric, you need to prioritize one. You have to have one metric that you say, hey. This is the metric. That I'm going to prioritize as my not star metric. But I'm going to have a bunch of metrics that I'm gonna use as secondary metrics that I'm also gonna talk talk about. Transactions is not gonna tell the full picture of the of the business. So I'm gonna have gross merchandise value and number of people who are making purchases daily as actually, like, secondary metrics. For example. But you need to choose one metric as an odd star metric. And it's very context dependent upon the company. Okay. Second thing that I wanna talk about about debugging metrics at work. Okay? So there's a set of questions that that get asked about Hello? Hey. Men on Tinder is growing faster, but women are not. National brands are going growing while artist artisan's stores are not. These types of questions. They're giving you a data point. And they're asking you to tell app what are you gonna do about this. Okay. So the place where I'm gonna start with is what would you do if you got that data point at work?  
Me: I would try to adjust  
Them: Okay. So let's actually, like, start there. So what would you do if you got some data point  
Me: how like, it's  
Them: at work? Actually, let let me just, like, spend Actually, let let me just, like, spend five minutes going back to the metrics thing. I just see a bunch of questions. I wanna, like, talk about that before we move move on. So I wanna touch touch on a few things with respect to metrics base metrics before actually I can move on. There's there's, like, a few nuances over here. One is if people are asking you, what is the North Star metric for an entire product? Okay. So what goals would you set for Airbnb? As a company? What what is your not star metric for DoorDash? What is your not star metric for Instacart? These are all, like, full product or full company level metrics. Okay. That's, like, one type of not star metric discussion that you can have. And then there's a second type of not star metric questions that you might get which are about you are never the owner of the full business in a as a PM. Maybe you are the notifications PM on DoorDash. What not star metric would you set for the notifications product experience in DoorDash? And what metric would you use to measure success? You are the trust and safety PM for Instagram. What not so metric would you measure? What what goal would you set and what not so metric would you would you set? You are the Airbnb what do you call it, guest host experience PM. You're the you're the Airbnb host experience PM. What not sub metric would you set for that? Okay. So you instead of getting the full product, you might get some leaf nodes of a product and be asked to set a goal and a metric for that. And there's differences in that. And I want you all to, like, just think about that. So if you get a full product, then it's the answer could be pretty straightforward. A lot of media products started, like, DAP, have secondary metrics around time spent per DAP and some counter metrics around stuff. But then if you're asked about, hey. Like, what would your creator not star metric be? Okay. Or your safety not star metric be. Then you're, like, going down. You're a growth PM. What would you set as the metric? Okay. So you wanna, like, think through not just, like, at the top level, but at different levels in a node. With respect to metrics. That's, like, one thing that I wanted to actually call up call out. The second thing to think about is that, hey. There is no one answer that is right for a not star metrics. It's like a discussion based on company strategy on what they might choose. Hey. Do you wanna go on total transactions? Or on number of daily active people or merchandise value or as DoorDash. It's like an interesting discussion to actually, like, have. And what they go along might change over time. Okay. When DoorDash first started, maybe the number could actually, like, just be daily active orders. Daily active people. You just want people to get on the platform and then you want retention. Maybe that could be, like, the thing to go after at that point in time because that aligns with the strategy. As you become mature as a business, maybe the the number to look for is total transactions. Or for a different kind of business, that has expansion of dollar basket size maybe the the thing to go on is gross merchandise value. Okay. So any of those three metrics could actually be good not sub metrics based on the company's strategy at that point in time. And that's the discussion to have in those interviews. The stage of the company and what is the trade off that you're making. Which metrics are you really thinking deeply about? And why are you making the choice that you're going to make? That's what people are looking for. Cool. So let's talk about you are given a data point. Some some you're given some data trend. And you were asked what would you do. Okay. When that happens at work, what do you do? You start by, like, and then and then it's like some data trend anomaly. Metric is grow some metric is growing faster, slower. It spiked. It fell off a cliff. It could be like a direct metric or it could be like some funnel ratio that acts like is not going according to plan, you get some trend. And what do you do then? You first start by doing some root cause analysis. And the outcome is, is this some operation and engineering problem? Or is it some product problem? That's the thing that you're trying to figure out with the root cause analysis. And if it is, like, an operational engineering problem, where is that problem coming from? And you actually, like, kind of think about, hey, like, is there measurement accuracy issues? Are there any platform issues? Are there issues? Are there product launch related issues? Are there any external factors that are causing it? Is there any marketing impact then is there a product experience or behavior impact? You're going through these types of things. And then trying to figure out, okay, where is the problem actually coming from? Okay. So there so that's the root part of it that you'll go through. You can look at measurement accuracy, like, is it logging? Like, are you querying the data accurately? In in, like, the dashboard you're creating? There a visualization in issue in some form? Like, platform issues, is it, like, device based, OS based, browser based? And then, like, infrastructure issues, is it like a hardware infrastructure stack, web or native integrations, partner integrations, geography, or any of those things. Is it like a product launch issue? Like, you release the some some feature? You look at, like, note at what's happening. Look at error logs. You look at latency, and is that causing it? Is your recommendations, Tammy? Like, has something changed over there? Are there, like, search navigation issues? And then if none of those, like, or it's, like, external issues, like, somebody launch company to launch a product, like, some issue happening in some country, it could be any of those. If you do that part of a root cause analysis. If any of those are true, you else fixes the problem. And if none of those are true, then what remains is could be a product experience, some user behavior issue, or some marketing impact that actually, like, is happening Okay. So that's the first thing that you would actually do. You do a root cause analysis, and then you say, okay. Hey. All of that is fine now. Let's go go and figure out what might be happening in the product. And what would you do if you get there? You go and then dig into the data. And understand if the data abnormality is for everybody, or is it localized to some segment or some stage of the funnel or some subs metric that actually, like, might be there? So you might do something like this where you take that metric and you actually, like, segment it in different ways. You take one factor of of segmentation, and then you see what the segments are within that, and then see how the metric is looking. You take a second factor, you actually, like, look it, and then third factor and then see. You see, is the anomaly localized to some segment based on different factors? That's what you do at work. And then what determines these, like, factors? Like, it could be segmentation based on what the product type is like we talked about. It could be acquisition channels. It could be customer life stage. It could be, like, some marketplace dynamics that are at play. So you cut the data by different segmentation factors to see where it might be localized. Okay. Or you might actually, like, dig into the funnel. Okay. If some metric is actually, like, at the bottom that you're getting is tagging, you might wanna see where in the funnel is that actually, like, happening. Okay. And then you can think about what the funnel could be different based on on the product type, media marketplaces, productivity of different types of funnels. And then, like, you can look at customers and actually, like, partners in some form of this. And then you can actually, like, see, hey. Where in the funnel is a drop off? And then you can actually, like, cut the funnel by different segments again. And you might see, okay. Hey. This problem is localized. In some stage of the funnel to for some specific segment. Or you do some metric analysis. You might say, hey. Revenue is dropping. Is revenue dropping because the total number of customers is dropping? Orders per customer is dropping or the average order value is dropping? And then you can actually, like, take the sub metrics and, again, actually, like, cut it by different segments. This is what you would do at work to actually, like, debug. Once you have a trend, this is actually, like, what you would do to localize the problem and you wanna, like, get at some specific spot in the funnel segments and sub metrics that actually, like, might be causing problems. And then once you do that, you then actually, like, see, hey. What product or marketing issue might actually be causing these data trends? So you might say, hey. Like, there is some funnel stage, some segment where there is a problem, Is it a product experience problem? Is it a ranking back end problem? Is it customer behavior psychology problem? Or is it a marketing sales initiative problem? And you'll have some hypothesis for them. And then you say, okay. Hey. For this segment, this stage, There's a product hypothesis that I have that could be causing issues. And maybe there's some marketing thing that could be causing issues. And you actually, like, create this set of hypothesis. And then you go and then validate those hypotheses. Which one of these hypotheses is actually true? And then when once you do that, then you actually, like, say, hey. If these hypotheses are true, so I could make these changes. And run a b test on those things. So that's what you do at work. If you are given a random trend of data, this is what would do as analytical thinking PMs. Figure out in the space, funnel stage, metric stage, segment stage. There is a the real anomaly is coming from, Figure out what the product, customer, and marketing hypothesis could be. Validate some of them if they are true, and then for the validated hypothesis, figure out what product changes you want to make. That's what you would do in real work. Now that's what they're asking you to do in an interview. Okay. So if somebody asks you a question like this, you're a PM at date Tinder, and you find that one percent of men get 90% of the dating request, what would you do? That is the question that you might get. If you get this question, you have to simulate all of those steps. And actually come up with what product changes might you experiment with. And that's what this is about. So, for example, like, in this particular case, the issue is already constrained by segment. They're saying, one percent of men are getting dating requests. The sec and then ninety nine percent of men are not getting big requests. It's like a segmentation constraint that's already been there. So you can identify stages of funnel where the issue might be. So what funnels what could be funnel stages for dating? Onboarding, matching, selection, and communication. Okay. When people are onboarding, what could be issues? When people when Tinder is matching people, what might be issues? When people are choosing who to swipe, what is the issue? When the people are communicating with each other, what could be issues that could be resulting in this problem? And that could be the final stages of it. And then what could be data hypothesis? Like onboarding, user settings at excluding majority of men. Like, there was a recent article about Tinder adding a high requirement And actually, like, there's a lot of data about actually, like, height choice being, like, pretty exclusionary. Because in there's some stat about some percent of men are about six feet in height, but eighty percent of women want only men who are six eight six feet in height. Okay. Settings could actually be excluding a majority of people. So that could be a data hypothesis that that you might have. Matching. Majority of men are not being shown to women at all by Tinder. Could be, like, for whatever reasons. Selection. Majority of men are getting rejected by women. That could be like a data hypothesis. Communication. Conversations don't lead to next steps. Could be data hypothesis. And then for each of these, you can actually generate product customer user hypothesis. User settings excluding men. Either women could be using filters excessively and the other thing could be that the app is honoring preferences strictly instead of actually, like, having ranges for that. Like, what's the difference between five, 11 versus six? Or five ten versus six? Like, should we draw the line there? And then for majority of men are not being shown to women, it could be recommendation system bias, there's different types of issues that could be there. It could be overfitting everyone every person. Per person based on them, it could actually be overfitting or high engagement candidates like, are overwhelming the system because we're not normalizing scores well. Or there's a cold start problem for new people who come onto the platform. Okay. So it could be, like, different product issues that could be creating this data hypothesis over here. And then men might be getting rejected by women. So maybe, like, hypothesis could be have unrealistic standards. Men don't present themselves well on dating apps, or make decisions without actually, like, getting to know the other person. K. Different product or user consumer hypothesis. And then convolutions don't lead to next steps. So people don't respond to messages. People don't start conversations well. Conversations die down as they get reparative or boring. It. Some product hypothesis over here. And then for each of these, you can actually, like, take actions. If these prove, right, what actions would you take? So if it's about user settings and then filters, then you can rethink filter options that you give to people You can educate people on the distribution of of different characteristics of people. You can consider not strictly honoring filters in some form. For recommendation systems, you can actually take a bunch of actions. You can have diversity mechanisms. You can normalize scores. You can actually, like, have cold start bootstrapping process that are much better in some form. And then for, like, unrealistic standards, you can have, like, dating coaches. You can have profile tools. That help people represent them better. You can have better conversation starters. You can have virtual speed dating, for example. In some form. And then for people, conversation not leading to next steps, you can have reminders, notifications, and some etiquette that you set on it. You can have, like, AI coaches to to help with, conversation starters. I think Tinder just launched something. Progressive con conversation coaching, where how do you where do you take the conversations next? So you can have some set of actions that you could do. So this is what it is, like, some form. You you are seeing, okay. Hey. This single thing of one person of men are getting all the dating requests. You can say, okay. Hey. Where could the problems be on a funnel stage? What the data hypothesis could be? What are the product and user hypotheses? And then what actions can I take? And you are simulating this in an interview. You don't have any of this data, but you're actually, like, saying, okay. You wanna come up with strong hypotheses across the board. And then the interviewer might give you some inputs on what might be what they don't want you to go down and why where they want you to go. But this is what the people are trying to see. Can you, like, think in a structured way to go from a single data point data point of one percent of men get all the reading request to what product changes should we be thinking about? Okay. And that's what it's about. And, again, like, if were doing it in, like, two hours, you should be able to, like, do this in two hours. In a thirty minute interview, you'll have, like, a much lighter version of this. And then if you have thought about a problem first and then you get it, you might actually, like, have a much better version of it in thirty minutes. And then the next thing that I wanted to, like, talk about is is product simulation also is is a thing that applies to trade off like, talk about it from product simulation perspective. So I see the jokes around actually, hey. Like, do you do this thirty minutes? Can you do this in, like, five seconds? Blah blah. I'll tell you this. Okay? Hey. You wanna actually get into a top tier company? You better be able to, like, do a solid version of this. In, like, fifteen minutes. Well, that's the reality of it. Okay? And and the if you if you think, okay. I'm bullshitting you, In my boot class clam, I actually, like, do these live things to actually, like, make sure that people understand that it is very possible. And I just ask people to just pull on what question they want, and I do it like. Okay. The expectation is that. Now how do you what what do you need to put in to get there? A real question for people to think about.  
Me: Exactly.  
Them: A lot of people fail in analytical thinking interviews at the top tier companies. Because they don't understand that this is a bar that people are looking for. Okay. Product simulation. So the thing is that you can't run an AB test for everything. Or even if you could run an AB test for stuff, to have a decision making framework for how are you gonna think about things. So if you are a PM at Canva, would you offer AI in the free version, or would it be part of only the paid version? Okay. Let's say that somebody asked you a question like that. What is it that people are actually, like, trying to get out of that particular response? So what people are trying to actually, like, see is, hey. Can you frame a decision well? And what does framing a decision mean? Framing a decision means that, hey. Like, can you come up with what are the options? And actually, like, what is the decision that you're gonna use? And, actually, like, what data do you need in each of the cells to make a clear decision for clear, like, value for for scoring. And then can you articulate what the trade off is going to be? Okay. So I'm again, like, giving you an example over here. And I could actually, like, have more options over here. So you can actually have AI on the free version. AI in only the paid version. You can have, like, some version of it where you say, AI some limited AI is available for free version. But if you want more AI, you have to, like, the paid version. You can have, like, an intermediate version in between. If you wanted it, you create those options. And then what is the thing that actually, like, is a decision making criteria? Eventually, you want to convert people into paid customers on Canva. So is that actually, like, going to help with that? Does it get people hooked on Canva, and does it lead to profitability? And that's the criteria that I'm gonna use to make this decision and I'm gonna take my options gonna evaluate against that And then I'm gonna say, okay. Hey. Here is a trade off. And as a result of that, I'm gonna make this specific recommendation for this. And that's what people are expecting you to show. And then you can have a conversation about, hey. This cell value I would run an AB test to understand that. Okay. So I want to know what the conversion to pay is gonna look like If I gave AI in the free version, how is it gonna drop? Or is it gonna rise? And I wanna understand that. And I wanna run a AB test for that. Okay. And in a different case, you might wanna do some user research, qualitative user research understand the cell color value. And you want to be able to articulate that. Can you set a very clear decision making framework with options and the criteria you're gonna use and where might you need quantitative data and then where might you need qualitative data And if you had to make a decision right at this moment, what assumptions are you gonna make? And what recommendation are you gonna do? And that's what the expectation is. Okay. That's what people are looking for. K. So I thought you answer this. And, again, like, if you were getting, like, trade off questions, like, like, the music time is going down, but podcast time is going up. What will you do? You would again, like, try to build something like this. But you start with what is the strategy for company. And what truly matters for the company. And as a result of that, what the decision making criteria that we have And as a result of that, what should we be doing? And that's the conversation to have. And you should be able to, like, set up a trade off metrics for that. And why? If you got the question of, hey. Do you want hundred reels with 1,000,000 views? Or a million reels with hundred views each. What would you do? So there, I might actually create more options. Hey. Maybe both of those are not that great. I might want some intermediate option where I want a hundred thousand reels, 10,000 views each. And I'll create an extra option, and I'll lay out what the decision making is and why. And then actually explain what the trade off is for me. Okay. So that's what I wanted you to, like, take away. Like, three clear concepts of how to think about base metrics and how the company's mission purpose ladders up to how you think about setting an English language definition of success, which is a goal. And then pick metrics that actually measure that definition of success, and that's how you do met base metrics. You're choosing between an aggregate metric, a customer metric, and a partner metric, and what stage are the you're actually, like, going to go on.  
Me: So  
Them: So that you can measure the goal, you can impact the goal, you can actually, like, have measurability of the metric itself. That's what I wanted you to take away from core metrics. When you are asked these questions about debugging metrics, I wanted you to think about, hey. How would you do it at work? And then now you're trying to simulate it inside an interview. Where you have, like, some data hypotheses you have some product hypotheses, and actually, what actions you would take based off of that. In a third in a fifteen minute interview, you're going to have, like, a few few buckets of these things. Not it's not gonna be as exhaustive. But it's gonna be, like, sparser, but it has to have clarity. And then when you're thinking all these, like, product simulation and actually, like, trade off kinds of things, what you wanna get at is a decision making framework with clear options clear trade off criteria, and then what the implications of it are, what do you want more quantitative information for, what do you want more qualitative data information for? And then being able to talk through that. Cool? So that's what I wanted to share about analytical thinking. And I'm gonna, like, pause and stopped. Cool, folks. Okay. It is ten fifty. I hope this gave you, like, a flavor of analytical thinking. Let's take a ten minute break then we will be back at 11:00. Think with this, what I want you all to, like, take away from this is how to think about these interviews. I think that that's fundamentally, like, what I want you to think about. And the way way I think about this is in these kinds of questions or behavioral interviews, you get asked a question. But people never truly understand what is the question that is being asked. And I think that that's the seed that I wanna put into all of your minds. When somebody asks you, hey, tell me about a time where you fail. Okay. That is what was said. But what is the actual question that people are asking you? And why are they asking you that question? And if you knew that, maybe you would give a different answer than whatever you gave in the past. I think that that's a fundamental frame that I want to change for all of you. When somebody asks you, hey. Tell me what time when you failed. They're not looking to be your therapist. They're not looking for your soft or my sob story when I fell. That's not what they're looking for. The real question that they're asking is tell me about a time where you failed and you learned some important lessons and you went about and made changes as a result of those lessons, and you became a better person and a product manager as a result of making those changes, and you now have proof that you are a better version than the previous version. That's the real question that they're asking. So if you knew that was a question, you probably would have a different arc to your story than if you heard the question or internalize the to be, tell me about a time that you fell. Okay. And that's the key thing. What's the real question? And why are they asking you that question? They're asking you that question, because they wanna learn about how much do you focus on growing yourself. And are you capable of growing yourself? If we hired you today, in a year from now, will we get a better version of you than the version that you currently are at? That's what they're trying to evaluate. Okay. That's what I want you to take away from this. Truly understand what is the real question and why are they asking that question. If you knew that and if you could articulate that, responses would be completely different. Okay. So, I think that's the first part that I want you all to, like, start with. So then I'm gonna, like, try to simplify this down for you all So we talked about this. I think I had these slides. But I want to start with this. Okay. So let's talk about this. What is it that they're actually trying to evaluate you for? Okay. So the thing that people are trying to evaluate is, hey. This person proactive? What does that actually mean? It means that this person identifying problems or opportunities on their own? And these problems could be product opportunities people opportunities, and process opportunities. But are they identifying them on their own? And then are they taking initiative to develop a plan? Hey. I see a fire burning over there. Great. I saw the fire. But did I do a damn thing about it? Okay. That's what actually I'm thinking about. Taking initiative, to actually, like, say, okay. Hey. I'm developing a plan on how do we solve that thing. And then do they have the ability to get some people to volunteer There's a small fire. I can throw a bucket of water and end it. There's a big fire. I'm gonna have to, like, go big bring a bunch of other people who can help me with it. And do I have the capability to go and then get a bunch of people and volunteer to actually, like, do this stuff? And then at some point, it's going to be something that volunteers can't do it's gonna be a much bigger thing that there. Can I go get buying for resources for that thing? And that's what being proactive is. And they're trying to evaluate people for that. And they're trying to look for proof of that. K? And then ownership and accountability. What are they trying to actually, like, evaluate? What does ownership and accountability mean, like, in some form? Can a person bring clarity the first step of taking ownership is to actually get to clarity on what is it that we are trying to do over here. What is the outcome that we're trying to draw, to to get to? What are the plans? And who is doing what. Okay. Clarity on on our purpose. Our plan, responsibilities of people. And what does ownership mean? That you're willing to do whatever is necessary for the project success. Or are you gonna say that's not my job? Okay. That's what people are trying to I'm Restauros. Founder and CEO of ownership and accountability. Being able to think about what challenges I might be facing as a team and how do we plan for that? How do we actually, like, get ahead of those things? Okay. And then how do you get decisions made? Because you don't make all the decisions. You have to get decisions made by And can you get those decisions made? And then can you take accountability for mistakes that happen and actually learn from them and then move forward. And that's what ownership and accountability is. And then are you resourceful and resilient? So you never have what you think you need to get something done But can you take whatever you currently have and then get momentum? With the resource constraints that that that are there? Can you find creative solutions Can you rally a group of people to do more than what they believe they can? Can you push yourself and your team And when things don't go according to plan, are you gonna sit in and sulk and then waste days and months, or are you gonna just bounce back and then keep moving forward? K. And then can you actually get buying from people to get help you in different ways? That's what resourcefulness and resilience is. And then you are de facto the leader of the team without actually, like, having having any authority So can you resolve conflict? And the conflict is not just within your team, but it can also be with other teams with actually, like, leadership and how you are supposed to resolve that. At a certain level. And somebody demonstrate that they identify conflict early? They don't let it linger fester and become bigger things. At the first side of conflict, you actually, like, lean into it. Do you facilitate open communication with people so that people actually talk about what the issue is so that they can solve it. Do you view it as an opportunity? Stronger alignment? Issues that are actually buried out in the open everybody is now rowing towards the same direction. How do you view conflict as a negative thing? Can you actually, like, manage your own emotions where actually, like, their high stakes conflict's happening? Can you show empathy and be respectful to the other people? So they feel good about themselves when there is a conflict is resolved. And can you actually get alignment? Eventually, you have to resolve the conflict. After all of these things. And you have the capability to do that And that's what people are trying to actually, like, evaluate. About conflict resolution. And then people are going to evaluate whether you can grow yourself can you grow your team. So fundamentally, do you view yourself as a fixed thing? Hey. These are my skills. I'm done. Went to school. I'm out of it. I'm done. Or do you view yourself as somebody keeps going? View yourself as a versioning system where version n plus one is better than n. And every year, there's a new n is actually happening, and the better version of you is coming. You view yourself as that, or you view yourself as, okay. I'm done growing. I'm like, this is who I am. Live with it. Are you self aware of your gaps? And are you, like, intellectually honest enough to unlearn your gaps? Do you seek feedback to do that? Do you synthesize your learnings and can you actually, like, scale your learnings to apply to different situations? Okay. Are you someone who can generalize the learnings and okay. Hey. This this, like, a pattern of behavior that I have, that is hurting me in different ways. Alright. You're gonna be one of those people who's like, you you are asking me to do this exact Right? Are you gonna be that person or you're be like, hey. I make these pattern of mistakes, and I need to change that across the board. Are you energized by working on challenges? And then do you help your teammates with their challenges? You know, that's what people are trying to evaluate. Okay. And there's, like, two parts to this. One part of it is that hey. This is what people are gonna evaluate you on. As a PM leader. So if you want to tell good stories, in interviews, you need to embody this stuff. And live that life. Be that leader.  
Me: So  
Them: So that you can have stories to tell. So if you think you don't have stories for any of these areas, And if you have a job right now, create situations to build that story. Demonstrate that that skill. Okay. That's the first thing that I'm gonna tell you. This is what people want. This is what people are looking from for PMs. So start embodying that. Okay. And then if you don't have a job, to actually, like, embody that in different places. Bring the peep group of people to do something together. To show your productivity. Like, show some accountability with some group that you're doing outside, whatever it is. If you have gaps in these stories, do that work to create those stories. And then the next thing then is that in an interview context, you wanna communicate your stories extremely crisply. And the way that you do that is by doing a lot of writing of your stories. And you wanna write your stories in a way in which the interviewer is gonna write their interview feedback. And the way that I think about this is let's say that you're trying to you you ask a question. Tell me what a time when you get you got buying for an idea when nobody believed in it. The first thing to recognize is, hey. People are actually, like, trying to see if I am proactive and I'm, like, resourceful in some form. That's what people are trying to evaluate. And then what would a successful interview feedback look like? Okay. Successful feedback. If I was writing a feedback, it would look like something like this. Where I write a summary, This person proactively identified some user problems, They were resourceful in getting some bind and solve the problem leading to x result. That's what the summary is. I'm gonna have some details, and the details are that at company x while working on product area, y, they noticed some insight and identified some opportunity. They took some actions. They recruited a couple of people to build a product to show value, They pitched it to leadership team and got buying to invest in that project. And prioritize in the road map. They launched a new product. That's the action that they took. The impact, the product, the feature led to some result. Okay. This is what I would write as an interviewer. If somebody was a high quality candidate who showed proactiveness and resourcefulness, this is what I might write. Okay. And that is what the interviewer is looking for. Why not write your stories in that way? Okay. You can write your story like this. And then actually, like, say, okay. Hey. What was the product area? What was the company? What was the product area? What was the insight I saw? What actions did I take? I got buying and I had a made scrap scrappy progress. I got some resources. I executed on the project. I result got in this result. So write your stories That way, demonstrating the exact types of skills that people are trying to evaluate you for. And remove everything else. Remove everything that gets in the way of you landing that story. Okay. And then for each of these skills, there are some things that are positive and some things that are negative when they appear in your story. What is positive? You identify problems and opportunities on your own. Positive, Taking initiative. Positive, getting buying, positive, getting people to volunteer, positive, producing measurable results positive. What is neutral or negative when you when people ask you some a question like this? The problem was given to them by their manager or leadership. Neutral to positive, negative. Waited for their manager or leadership to get buy in, negative, Gave up when there was feedback from the team or leadership. Negative. Was stuck because they could not get folks to volunteer a prototype. Results are unclear and not measurable. When I show you this slide, you might think, hey. Negative things seem very pretty obvious. But you'll be surprised in how many people spend a lot of time telling these negative things when they're asked a question like that. I also did it. Okay. So because the fundamental thing is to actually know what is the thing that people are looking for. In every experience that we have at work, there is a bunch of negative stuff that happens. That we feel wronged by. We think that somebody did something that they shouldn't have done. Somebody didn't believe us. Somebody actually, like, was unnecessarily pushing back on things. We have all of that junk. But that junk has no place in an interview. And we take all of that junk and tell that story because we did not think through what is the actual thing we should be saying. What we shouldn't be saying in an interview. And that's why writing your stories down is super important. And removing everything that gets in the way. And then somebody asked, is giving up really bad? Wanna start the hill not to die on. Giving up is not bad. But in this particular case, that story is not answering this question. The question was hey. Tell me what a time when you got buying for an idea. If you did not get buying for an idea and you gave up on that idea, then that is not the story to tell in this particular situation. That is all I'm saying. Pick a story that actually answers the question. And demonstrates the skills that they're trying to evaluate you for. Okay? That's all I'm saying. Same thing with Same thing with account accountability. So for example, if I was evaluating some candidate, and I had to make a case that they take accountability and ownership. I'm gonna write a summary like this. They took extreme ownership for a complex company wide project. They worked through a number of product and people challenges. They successfully landed Impact. They took accountability for things that they did that didn't work out and made necessary changes. That's what the summary would be. And there's gonna be contacts what company, what product area, what was the complexity. What was the complexity that actually, like, they were solving for? And then what actions did they take? They brought clarity. Have made sure that everybody understood what it is. They develop clear plans. They obstacles, and they face those obstacles in certain ways. And they made some mistakes. They learned from it, and they landed impact in some way. So write your stories to actually make that case. Very clearly. What is the thing? What are the what are the attributes that people are trying to measure? And what things are going to demonstrate those attributes. Somebody else can use nonprofessional stories. You're interviewing for a PM job and the question is about PM work, stick to PM work. K. Again, what is positive what is negative? Bringing clarity, doing whatever it takes, anticipating obstacles, making decisions fast or getting decisions made fast and unblocking the team, taking accountability. What is neutral to negative? It's unclear what the goal of the project is. Okay. They get stuck. And then they blame other people and situations. They make mistakes that they could have been avoided. They let decisions linger on for too long without getting them resolved. Like, they blame others for situations, and they don't have learning from it. You would be surprised how much of this negative stuff people tell in stories. I also did. Okay. So when I was telling a story, when I was interviewing at Meta about Vine, there was this angle that was sitting in my head about how I was right execs was wrong, and I proved them right approved them wrong. I told the story with that underlying thread in between, but I that could have easily been the thing that killed my interview. It I It I could have told the story in a much better way, but I was holding that negative thought. That, hey. They didn't get it when I was selling them. It took me so long. Why did they have to, like, fail to actually, like, learn the lesson? Okay. So just telling you that, hey. This is just, common common thing that's that happens to people unless they're intentional about how they tell their stories. Growing south and then team, Again, what would I right. So question is, tell me what a time when you got strong feedback from your manager. Again, see, the question that was asked was, tell me about a time when you got strong feedback from your manager. The real question, Tell me about a time when you got feedback from your manager and you learned some in spite insightful things about yourself. You went and actually, like, made some changes. And that made you a different person. And that got you some results. That's the real question. So then and what is the person trying to evaluate? Is this person going to grow themselves? And a summary that is a good summary is, hey. They received feedback. Self awareness to identify their role in that situation. Additional input in how they could have handled the situation differently, develop some new skills, as a result of the new skills, saw more impact. That's the summary I wanna write for someone. If I'm gonna make a recommendation to hire them. To write the story in a way in which I can actually extract that out. K. Again, what is positive and what is actually, like, negative? People viewing themselves as virgins. Being self aware of skill gaps, seeking feedback, synthesizing and applying learnings, being energized which by challenges, supporting team development, What is neutral to negative? They view their skills to be static. They already are great. They don't need to grow. Like, people don't misunderstand who they are. It's their fault. They look externally for things that they don't control instead of internally. They don't want feedback. They don't take feedback. Again, everybody does it. I've done it too. Like, I've lost, like, significant carrier moves by actually, like, not accepting feedback at some point in life. Like, they know how to, like, generalize learnings. They avoid challenging situations. They're self centered. Don't invest in their team. K. Same thing with resolving conflict. Like, what is there somebody like, hey. They are anticipated. Cross out prioritization to be, like, a a touchy issue. They collaborated with the PMs on the other to understand goals. They framed the trade offs and options, drove cross org alignment, they unlocked the teams. Okay. In some form, that's what I wanna write. So think about stories that you can actually tell way in which people can say, hey. This person anticipated conflict took actions to resolve them, and as a result, actually, like, strengthen the relationship between the teams. Cool? Last thing I wanna talk about is product thinking framed as behavioral questions. So sometimes, like, questions you get are, hey. Tell me over a time where you build a zero to one product. And then over there, people are trying to understand what is the question over here. Tell me over a where you built the zero to one product, I wanna understand what your product strategy was. Which means that, hey. What is the context What segments were you going after? Problem were you solving and what you built? What was the execution challenges? What did you find out in different points in time? How did you make decisions? What and then what were the leadership challenges? And how did you actually resolve them? All of that is actually, like, masked into that simple question of tell me about a zero to one product. That you built. And you wanna, like, tease out based on the interviewer what are they looking for? And the way to answer that is to actually give them like, a one or two minute one minute summary or two minute summary of all these aspects and then ask them, hey. I can go deeper into any of these things. Tell me what you want more information on. And then actually, like, go deep on where they want you to go. Okay. That's how I think about it. So I wanna talk about telling great stories. So at a macro level, I want when you're writing stories, like, a few mental filters for writing great career stories. The first thing is, set up The fundamental thing that you're trying to do with setting up people is that you're trying to transport the reader into your situation. People should be able to understand your problems in specific detail. Even if they knew nothing about your industry or any of those things. What the setup is. You wanna, like, literally make them feel like they're watching over your shoulder from x years ago when you were in that situation. And that's what setup is. And you should be able to, like, do that in a couple of sentences. You don't need, like, minutes of rambling to actually do a setup. In, two or three seconds, or two or, like, two or three lines, can you get them there? And that's what the setup is. And then altitude, Altitude is how do you frame a story in a way in which people who knew nothing about your industry understand the exact specific problem, trying to get at. And that's what you need to figure out. People are always like, hey. My product is super complex, and I can't actually do it. And I'm like, hey. It's just because you've not done the work to actually, like, get it simplified. And then progression. Every sentence should encourage the person to read the next sentence. And you do that by moving the story forward significantly with every line and creating suspense. People want to know what happens next. And that's what progression is. And then action Every line should show progress against what you said with the problem or the opportunity and you are, like, revealing an intermediate outcome. Every line should actually, like, have an action and an outcome. And that's how you actually move the story forward. And then eventually, you have to accomplish it. Whatever you said the problem was that you were tackling, you need to have solved it. And it needs to be measurable. If it can be. Language write like you speak, use fifth grade vocabulary. And then editing,  
Me: Yeah.  
Them: remove everything that can get in the way of you landing your message. Read it and say any line that can be misinterpreted or viewed negatively, remove it. K. Write a first draft, let it sit for a while, and then rewrite it. And then write it in half the words. You'll be surprised at how few words you actually need. K. So trim things down. And then speak it out. And then see what the gaps are in the story because you're you're using a different sense and then actually, like, fill those gaps. Okay? That's what filters for writing and editing your career stories. Setup is transporting the people to where you were x number of years ago. Altitude is to help them understand the story even if they did not know nothing about it. Progression is actually, like, encouraging the people to read your story by creating suspense. Action is actually making enough progress towards an outcome in every line. Accomplishment, you should solve the problem, and it must be measurable if you can. Language should be simple. Editing, you remove everything that gets in the way. And then you should speak it out to actually make sure that you're not missing anything. K. So that's what my my filters are. Correct? So it's 11:30, so I'm actually going to switch over to XFN partnerships. K. So I hope this was helpful. I think the fundamental thing that I want you to take away from from this is a few things. One is, is the question behind the question. What is the real question are they trying to actually, like, evaluate you for? Try to actually, like, be explicit about that. Okay. And then there's, a core set of skills that people are trying to evaluate you for. Whatever they call them. And then you wanna demonstrate that each of your stories, And when you're writing your stories, write it in a way in which an interviewer would like, write their interview feedback, to demonstrate that skill. And then tell the story in that way. Okay. And then have some filters on how you actually write your stories. So accept in relationships, I wanna give you some principles about how to view your accept and partners. Cross functional partners like PM, designers, engineers, data scientists, user researchers, and what are the things that they're evaluating you for interviews when actually, like, you're evaluating you're being interviewed by by an EM. You're being interviewed for a design manager. What are you actually being interviewed for? Just trying to see. Okay. Just trying to see. Okay. Do I wanna tell a story? K. I'll tell a story. Okay? So so I'll tell a story. Someone answer Someone answered this question of, hey. Tell me about a time where you fell. Wait. Tell me about a time where you fell. This is is a is a question that that let's say that's a question. Let me think about it for a second. In 2018, I was the product lead for in the Facebook app working on a product that was Facebook discovery, which was gonna be IG explorer, but in the Facebook app. And I had a great sponsor on that product team. And it was a amazing opportunity for me to build out a new product the inside the Facebook app. And actually, like, have I was successful, I would have significant career growth in that space. The challenge that I faced at that point was that there were two other teams inside the Facebook app who were also solving similar problems and all three teams were actually competing for both real estate inside the app and for who was going to drive that particular initiative. And the other two people who were driving those initiatives were significantly more senior than me in the company. Were much more skilled with navigating organizational structures and also a little bit with sharp sharp elbows. And during that project, I did not have the skills to navigate that level of overlap in product space and organizational challenges And as a result of that, I made some mistakes in how I navigated people relationships. And as a result of that, the other two people escalated to my manager and I was layered And my project was given to the new manager that I got, and I was given a smaller space in that. And that was pretty devastating for me from two ways. One was that I had lost out on a clear career growth opportunity. And two, I lost the trust that my sponsor had in me. And I struggle to deal with the loss sponsorship or or the the trust loss that actually, like, happened. And I struggled with it for a while, and my sponsor got me a coach. And through that process, what I learned was that I lacked some specific skills around anticipating organizational overlaps and how to navigate those better in a way in which I externalize the conflict and focus on solving it without actually, like, letting the interpersonal dynamics get in the way of it. And I learned that that was what was the skill gap that I had. And I focused on figuring out how to solve that and the way that I went about solving that was by watching and talking to a couple of people, were working in similar higher stake situations, in different parts of the org on how they navigated those areas, I then actually found myself a role where I was again working on similar high conflict situations and applied those skills and actually, like, did better to a point where other people complimented that I just don't lose my cool at all. And I earned the reputation of someone who can actually be dropped into high stakes situations and would actually, like, resolve and get alignment on those things by the, like, time I left Meta. So the that moment in time I fail felt and, it it was very uncomfortable. I lost out on career growth at that point in time. But out of that, I realized that I had a gap in this particular skill. I fixed that skill by actually, like, learning from other  
Me: Mhmm.  
Them: and watching them operate. I applied those learnings in a series of situations and demonstrated that I could actually, like, thrive in similar situations later on earned the reputation for being great at that. By the time I left. So that would be the story I would tell. So I think I took about four minutes that story, Rafi. I think people can ask me follow-up questions. Like, if I was in an interview, people can ask me follow-up questions. And I can actually, like, answer that. And the thing that I'm actually going to also repeat for you all is that I don't have I haven't written that story. I just actually, like, went from my mind telling that story If I wrote that story down, I'll be much more crisper with it. I'll be precise with how I wanna talk about it. There are, a few things that I might take out. I might take out, okay. Hey. People playing with sharp elbows. Maybe not actually, like, the right thing to do with in that story. Like, I might take out a bunch of things. Out of this. Elevate the story one more level. If I wrote the story and then actually, like, practice it once and then told it again. Cool? 37. I wanna actually, like, stick to time. So accept in partnerships.  
Me: I I  
Them: Somebody says Facebook explore fail at least three times. Yep. There's a story behind it. It does yep. So this challenges in there. So XFN partnerships. What are the people trying to interview when people interview you, when an engineering manager interviews you or, like, a design manager interviews you, what are people really trying to understand? They're trying to, like, see if, hey. Can this PM talk with different functions effectively? Which means that do they have empathy for the other functions and can they build a working model with them? Can the PM adapt to the capabilities of their peers? Based on actually, like, the levels of the people? The junior people, how do they work? Senior people, do they how do they work? Can this PM set up good execution cadence for the team? Do they do good project management? Can this PM like, leverage the entire team well? So can they actually, like, delegate work well? Can they actually, like, are they territorial, or do they actually, like, share the PM work up to other people so it actually they get more out of the team? Will the team have a voice in product direction? They empower the team? And then will this PM create space for people to shine or are they actually, like, going to shine the spotlight on only them? Do they create do they give credit and visibility to other people? Okay. So that's what people are trying to evaluate when actually, like, they do these x f n interviews. And what do I want you all to, like, take away from it in the next ten minutes? And then the second thing that people actually, like, evaluate is let's say that I'm an EM. Do I trust this PM with the success of my team? Okay. So my career and my entire I team's career is gonna be dependent on how this PM performs. Can I trust this person with that? So they also try to evaluate your product thinking and execution if they're really good EMs. Okay. So that's the secondary thing that actually, like, people are gonna be interviewing you for. So I want you to actually, like, think I want to just see two things. So one is about empathy, and working model. Form with with respect to how you how you think about your peers. And, again, I sucked at this stuff. So so I got in better over time. So the fundamental thing is that when you think about people, everybody on the team has some set of common incentives. Everybody wants to have impact. Everybody has growth areas. Visibility. Everybody wants to help build the org, and everybody is, like, future planning. They're common incentives. For people. But then based on which function you belong to, there are incentives that are specific to each function. And we all miss that. Okay. It's like this. Thing, the story that you see about, hey. Like, this six blind people standing around an elephant They're asked to touch the elephant, and they're asked, hey. What are you touching? The person who touches the trunk says it's a snake. The person who touches a leg says it's a tree. The person who touches a ear says something. Okay. So that's how a a product team is. In some form. What we are trying to do is we are to build a great product but we have a focus that comes from one specific direct in some form. So PMs, want clear strategy, fast execution, well defined healthy x f and team that's set up for the long run. Engineers or TLs are like, hey. What system redesigns you might we need to do? Is the engineering complexity? Are the timelines realistic? I learning new tech? Engineering managers are thinking about are the goals realistic, what is the how is the team help doing, each IC on my team have good scope according to their level? Is the collaboration between engineering and the other functions? Does the team feel empowered? Designers might be thinking, hey. Is the design consistent? Like, are we solving user problems holistically, are we just doing piecemeal stuff? Data scientists are thinking, am I, like, being, like, a just pulling data to do, like, sizing every day, or am I actually, like, working on interesting insights that change the product strategy? Policy is thinking about others. Do we have scalable policies Can we enforce the policies consistently? And they wanna look at against regulatory risk. Legal is trying to make sure that your meeting the laws in the strictest definition possible. Whereas you might be like, hey. I wanna be in the loosest definition possible or whatever it is. Sales might be, hey. Are we responsive enough to the market needs in some form? So everybody is looking at the product through lens at a much deeper level, than others. And unless you understand why your peers are actually, like, asking you about different things, why they're holding the line on something you can't have empathy for them. As a PM, so many times I've talked to designers where we just do this design? Can we just, like, change this thing? But you don't know how much they are actually getting pushback from the design leadership for not actually, like, holding consistent designs, and they're being viewed as a bad designer because they are not holding the line on good design standards. If I didn't have empathy for that, then I can't actually, like, be a good for them. And that's fundamentally what I want you all to, like, think about this. Okay. So have empathy and understand what people care about in some form, in addition to the common things. The next thing that I wanna talk about is that don't view your cross functional peers as competition. View them as a way to scale yourself. Okay. Functions overlap at senior levels. That's one part of it. Okay. So everybody like, all functions have influence product strategy as part of their their evaluation criteria after some level. And then some of your peers might actually, like, want to become PMs. Or wanna explore being a PM. So just be open to that. At any point in time, somebody on your team wants to be a PM. None of us was were one PM. We all had some other job before we became PMs. Except for RPMs and APMs at a few companies. Okay. So understand people's carrier aspirations, what they wanna do, how do you how can you actually, like, enable that? While actually the team is successful? Okay. Play the long game. Winning is talented people wanting to do more work with you on more important projects. That's the fundamental thing. And I have to, like, change my mindset significantly for this thing. And then what do you want what people are expecting is what is a working model? What working model has two things. One is what do you view as a role of a PM? Versus what do you view as a role of acceptant partners? What are shared responsibilities? What is the PM accountable for, and what is the partner accountable for? Do you have a mental model of that, and can you articulate that how does that jive with what they think? Okay. The fact that you're flexible on that based on the company you're working with? Actually, like, people who are over there? That's the first thing that people are looking for. Respect to working model. The second thing is how do how does a day to day collaboration work? Between with different functions? So for example, how do you find responsibilities? How do you work on a project together? What do you meet? What is the collaboration style? And that's what people are actually, like, looking for. So for example, if I'm working with, like, a designer, like, the fundamental things that I wanna do that I want to align on a few things. Upfront. What problems are we solving? And what are the constraints for the solution? What are timelines to finalize designs? What are the intermediate milestone What product serve you reviews do we need to do? What team feedback do we need to get? Okay. So I wanna align with them on that. Then I'm gonna have some working cadence. Where I would meet with them one on one like, some cadence. Like, I'm gonna meet them twice a week or actually, like, daily if it's, a super intense project. We brainstorm directions together. They go and actually, like, do the design explorations. Get it back, and then we actually talk about them together. We shortlist ideas to go deeper into. They actually, like, go and then flush them out and get more richer designs. We then actually, like, figure out one or two paths that we wanna go down. Double down on them. We fine tune the designs. We work on a deck together. I work on some piece of the slides. They work on some piece of the slides. We run a review together. I do the setup and support them. Run portions of explaining the design to people. And that's what my design working model could look like. And I might have a similar thing about how do I work with data scientists. Okay. How do you defend responsibilities? I could actually talk about Then I might have a mental model about how do I work with people who are I see four, five versus seven and eight. How do I actually, like, change my working style with them? Okay. So with more junior people, I might actually, like, be more, like, pair programming with them. I do the work with them. I have very clear I want them to have very clear action items before they'll leave the room. I do the project management for them. Where the super senior people like, I just give feedback. They run the project. They set the schedule. They show me a calendar. They actually, like, come up with with with ideas. They just get lightweight feedback from me, and they keep going. Okay. And that's what I talk about in working months. And then do you And then you set up good project management. And people are actually trying to evaluate you for that. And then do you actually empower the team? Like, is there transparency? Do you are you inclusive? Like, do you explain decisions that you say somebody said so. Okay. Do you have shared responsibilities for different parts of the team? And then you give them credit and visibility. Okay. Do you give them credit in weekly updates? Do you actually, like, let them have voice and reviews? Do do do let them present in all hands versus you being the one presenting in all hands. Do you send thank you notes to people? Do you write performance feedback for them? Those are all the things that actually, like, add value to people, and that's what people are looking for. Are you a good partner to work with? And your interview questions kind of actually, like, have to answer that. Do you have empathy for them? You have a good working model for them. You let them shine. You give them, like, empower them. Do they have a voice in with what product is getting built? And that's what people are trying to interview for, and your responses need to actually land there. You need to first become that, good partner, and then you need to tell your stories to actually, like, explain that you're gonna be a good partner. And then finally, show care for people. Okay. Whenever I work with with people, I, like, understand I try to understand what the career are for all the people that I work with. I try to mentor. People in other functions. On the skills that they are interested in. Like, help them with writing, with creating decks, with improving their communication, whatever they want. I go out of my way to actually, like, help people with promo packages. And actually, like, performance feedback. So yeah. So show care for the people that you work with. And if you do that on a day to day basis, it actually comes through when you talk about them. When you talk about some relationship with some designer, like, how much care you had for them shows up in the way that in in your face. It's as simple as that. Okay. When I talk about people who I had great relationships with, work with, it's actually gonna shine through. And you want that to come through. Okay. That's what accept and relationships are about. So I think I'd like I think I have, like, a super lightweight thing about hey. Like, when you're doing project management, you wanna be clear about what the goals are, what are the work streams, are the people, what roles do they play, who is accountable for different components, what are the timelines, How does the team collaborate? Who are the stakeholders and decision makers? How do decisions get made? What are the upcoming decisions and reviews? And you need to, like, have all of this in one place, in one document. And just call it the canonical document. And you should, like, have a simple set of things like that. To actually do that. And you need to have, like, talk through Okay. Do that and then actually be able to talk through Cool, folks. It's 11:50 So that is what I had about, except in relationships and leadership. Recording stopped. So we'll take a ten minute break. Till twelve. Recording in progress. So let's talk about verbal skills for interviews. The way that I wanna, like, think about this is how do we work day to day versus how do interviews work, and how do you make adjustments for that? So the way that we normally work is we write a document, by thinking over multiple days, and we can start over as many times as you want. And then you can edit it. You can iterate on it multiple times. And then you can go back and then look at it after some time. You can catch mistakes. Actually change make changes to them. And then people you can get help from on the document, and eventually, evaluate the fine like, final version of the document that you wrote. Wrote. That's how we normally work during our daytime. But what happens a verbal interview? You have to figure out candidates have to figure out the answer in a couple of minutes. You have to speak out the response. You are like, out pieces of the response as you go along, and then you have to speak out the response. In pieces. And the interviewer has to listen to what you are saying, understand what you're saying, and capture it in real time. And the interviewer has to ask follow-up questions to get extra information that they want. And the candidate has to actually understand what the follow-up question is and respond to that in real time. And the interviewer evaluates candidates based on the notes that they took. Okay. They evaluate you not on something you wrote, and maybe not even what you spoke but they evaluate you based on eventually what were the notes that they wrote down about. Your response. Okay. So that's what happens. A verbal interview. And what gets the way of actually, like, having great verbal interviews? There are issues on the candidate side, there are issues on the interviewer site. On the candidate side, the candidate may not actually be listening well. They mix up thinking and speaking. They lack precision and brevity. They are operating in fight or flight collaboration mode. And they're not managing their time well. And from a interviewer side, the interviewer's mental state determines how well interview goes. And the interviewer's interviewing capabilities also could dictate how well your interview goes. Okay. So that's what gets in the way of interviews. So let's talk about what gets in the way of interviews and then what can you do about it. So with candidates not listening well, the problems are that they may not capture the question correctly in the first place. They don't understand true essence of the question. They don't really get what is the actual like we spoke about with leadership interviews. What is it that they're trying to get at? And then they're not listening to the feedback that the interviewer is getting. Anytime, the interviewer is getting frustrated in an interview, highly likely that's happening because they're trying to give feedback to the and the candidate is not listening to them. So they're escalating by getting frustrated in the interview. Okay. So that's, like, what the problems are. And how you, like what deliberate practice can you do improve that? You improve your presence by doing breathing practice and physical mindfulness In order to get better at listening, you could type while you're actually, like, listening so it makes forces you to actually listen. You can repeat back what you heard to the interviewer so it forces you to make sure that you actually listen and you confirm with the interviewer that you heard them well. And then don't say anything for five seconds. After you've after the other person has finished speaking, so that it gives your mind a chance to truly understand what is the actual question over here. And then see what extra information do I need and ask for that politely. And practice this in day to day conversations with people. At work, at home, to become a better listener. And then the second thing, why writing and typing while listening? That's my cheat. If I had to listen my mind would wander. And the way that I make sure that my mind doesn't wander is by typing everything that I'm actually, like, listening to. That forces me to pay absolute attention. And the way that even the even more intense way of doing it is, in one on one conversations, share my document to the other person, and I'm typing right into it. That raises the bar for how well I have to be listening to the other person. And then by doing that, when I choose to, I can listen without actually, like, typing. But that's my deliberate practice. That deliberate practice forces the muscle of listening well. And then mixing thinking and speaking. A lot of times people say, hey. Explain your rationale. But explaining your rationale is very different than thinking out loud. Okay. So what problems people do is they one, start speaking without even thinking. And then two, they think out loud and share their raw thoughts in the jumble of mess that is there before they have gone into clarity. And how do you fix that? You want to actually do a few things. One, make it a habit. Of after somebody finishes saying something, say, hey. Let me think for a second. Make that your practice. And intentionally, let your mind think before you speak. And the second thing is in interviews, very clearly separate out thinking time, from speaking time. The thinking time is when you're writing on the whiteboard, writing into a whatever you're doing. Think first, refine your thoughts. You might edit it on a document. You might actually erase it and like, restructure your points. Do all of that. Thinking time. And once you're clear about what you wanna say, then say it. And you're switching between thinking time and speaking time, throughout an interview. And you wanna be you wanna practice being very explicit about that. Okay. And practice it in day to day conversations as well. And then people like Precision Brevity. So the problem is that people have this w shaped conversation where you have four things that you wanna talk about. You say everything about one, then everything about two, and everything about three, and everything about four. It may work when I'm presenting like this. You have a slide, you have anchors, you can see it visually. But if I didn't have slides, and I was speaking to you, if I did w shaped communication like this, it's really hard to follow along. And then people use too many words to say everything. And then they get repetitive. People are uncomfortable with silence. And they fill the silence with noise. And the interviewer has to figure out when is signal and when is this noise that they should tune out. And people have filler words. Okay. So those are problems. So how do you practice it? Do deliberate practice. Of t shaped communication, or mental private communication where you're saying, hey. I'm gonna talk about four things. One, two, three, four. Now let me talk about one. And you go deep into it. You talk about two, then go deep into it. That's what t shift communication is. And you can actually, like, use numbers so people can pull you back into it. The next thing is write down in bullet points what you wanna say and then anchor your speech off of that. That's exactly what I'm doing right now in my presentation. I have a few bullet points. I'm anchoring my communication off of those bullet points so I know what topics I need to hit. And what point I wanna make about them and I'm expanding on that. And then say what you need to say, and then stop. Practice that every day. You're talking to your kid? Don't need to say the same thing four times. Say it once and then stop. With your spouse, same thing. And then silence is uncomfortable. And you have to get comfortable with silence. Especially in an interview. People ask me, hey. Is it okay to say I'm gonna take a minute to think and then think for two minutes? Totally fine. You are uncomfortable. The interviewer is not because they know you have to think. So one, mentally get okay with silence. Two, your body is fidgety. So practice physical mindfulness. Rub your fingers. Tap your toes. Breathe for ten ten breaths. To get comfortable with silence. And then record yourself and then listen. Okay. That's how you get more precision and brevity. And then people are constantly in fight or flight collaboration mode. So what is that Like, somebody gives you feedback, there's, like, two two things actually over here. One is people give you feedback, and then agree with the interviewer without thinking. Because you want people, please. Or you disagree with the interviewer to prove that you were right. That's, like, one set of mistakes that people make. The other type of things that people make as a mistake is they're asking the interviewer to tell them, hey. What answer do you want? Tell me what answer you want so I'll give you that answer. Okay. And that is actually, like, another type of mistake that people do. The opposite of that is that as soon as the interviewer gives them feedback, they completely pivot to that some other direction. Okay. These are fight or flight collaboration models. What people really want in an interview is intellectual honesty. Okay. What they're trying to actually, like, say is, hey. You are my coworker. We are actually, like, having a debate. I have some input input How are you going to incorporate that input? That's what people are trying to do. So you you wanna, like, demonstrate competence, but at the same time, you wanna, like, arrive at an together. So when somebody gives you some feedback, you just want to actually, like, here's my mental model. You gave me some new bit of information. If I process it through my model, does the answer change? That's what you wanna do. And explain that to them. And then when you ask for input from interviewers, ask them background information. Okay. You don't know something about the product, ask them. You don't know something about assumptions, you can ask them. But don't ask about solutions. Okay. So that's the thing to actually think about when you ask for feedback. Cool. So that's my input on Feyi or Flight collaboration. The last thing is people not managing time well. There's thirty minutes you have to, like, get through your interview in thirty minutes. And the types of things that happen is that people lose track of time. People rabbit hole into one specific part of the question and actually keep getting lost in there. People get stuck and they can't get themselves unstuck. They get sidetracked on project on topics that are not relevant. To what is being discussed. And that's how people, like, lose track of time. Okay. So time, you need to have a mental model. For product thinking interviews, this is what the cadence of an interview is. Analytical thinking, this is cadence. Leadership, this is cadence. I have this expectation. That's the first thing to do. Then the second thing is, how are you gonna track time in an interview? You should know that, and you should be looking for time. Okay? And every x minutes, you should check where are you relative to time. You should check with the interviewer at least, like, a couple of times in the interview. To make sure you're on track from a time perspective. The second thing is that when you get into a rabbit hole, you always write things in a hierarchy so you can actually get to the next level of one level up in the hierarchy to reset yourself. And that's how you actually get out of rabbit holes. If you're stuck on a section, you want to switch to brainstorming mode. And brainstorming mode literally means that, hey. I have no judgment. I'm just gonna write down everything that comes to my mind. And then I'm gonna evaluate later. That's the easiest way to actually, like, get unstuck. Stop the judgment. Okay. If I ask you to come up with 10 ideas for something, the reason why people can't come up with 10 ideas for something is because they want to get to 10 great ideas in the first pass. That great is the thing that is holding you back from getting to 10. So drop the great and get to ten first, and then you can go and then look at the 10 and then see what three great things are there in that. Okay. So that's the mental model of the shift if you're actually stuck. And then let's talk Then let's talk about interviewer's mental state. What could the problems be? They're working on a project. They just had a team meeting. A product review might not have gone well. And they're rushing to your interview. Like, last meeting was not great. They're scrambling to find the interview room. Every time, like, finding an interview room that you were supposed to be in, like, is a painful process. Stuck in traffic on the way to work. They got into a fight at home. Or at work. That kid is sick. They got a call from school. Any of these could be happening. And on the interviewer's mind when they walk in, Okay? So what do I recommend doing? The only thing to do in the first couple of minutes when the interviewer shows up is to help them reset let go of all of the other stuff. Don't try to build a relationship with the interviewer because that's not what actually, like, they want to do at that point in time. All you really want the interviewer to do is forget their shit. And give you a hundred present % of their time. For the thirty minutes that they're interviewing you, you want them to give you your their attention. That's all you want. And what is the simplest way to actually, like, do that? Just ask them, hey. How is your day going? And that's it. Don't get into the thing. You ask a question, but you don't care about what they say. That is just a reminder for them that all of this junk is on my mind, I need to put that away. The question is literally a reminder for them of all of the junk that is in their mind that they need to let go of so they can be in the interview with you. When somebody asked me that question, how is your date going? When I walk into an interview room? It reminds me of all of the loose threads that are there, that I have to explicitly say, okay. Wait for forty minutes. That's what you wanna do to the interview. Nothing more. Don't over socialize with them at the beginning. Don't you have done LinkedIn research of them on them. You don't need to tell them that. And what you found out about them and how you are connected to them. Hold up all of that stuff for after the interview. Not at the beginning of the interview. Okay. All you really want them to do is to give you their undivided attention, and they have to set up the interview system. You want them to do is that, hey. Open up whatever is a note taking system to write your notes. Know what your questions are, have those two things ready so it when you capture notes, you capture the notes well. That's all I care about. Okay. I don't care about how your day went. I just care that you give me your undivided attention at this point in time. Until the interview is over. That's what you want to do with the interviewer. Good. And then interviewer's capabilities Like, what are the things that matter? Like, can the interviewer actually listen capture interview information? 90% of people suck at listening. It's a reality of life. Okay. Your interviewer could also be one of those people who does not actually, like, listen that well. And then the second thing is that based on actually, like, people's capabilities, The general thing is that in interviews, the goal is to just evaluate what question what response people give. But sometimes there are people who want a specific response. Or they are stuck with with actually, like, whatever their mental model is. So how do you actually tackle that? So with respect to actually, like, making sure that people can listen, you want to make sure that people are % present throughout the interview. And what do you do? Before you speak, you want to make sure so you're doing this thinking time versus speaking time. While you're thinking, I'm sure that they've opened their some other thing to actually work on something else. Because they can't just sit in and stare at you for, like, three minutes or four minutes. Right? So you want to grab their attention back. Every time you are speaking, you wanna make sure that you are actually, like, getting their % attention. They have switched over to you. Before you say anything meaningful. So what you do is you have a filler sentence. I've thought about this stuff. Now I'm actually gonna turn and say, okay. I've thought about segmentation. Now clear about what my segments are. And by saying that, you're actually making that person now start to look at you. And wait until you know that you have like, contact with them. All of the stuff that I just said, I've thought about segmentation. I know what my segments are. Zero value. I don't need that to go into notes. But next, my segment one, segment two, segment three, segment four, I want them to capture that. I'm gonna wait to get their attention before I start saying the valuable things. And I'm gonna do that throughout the entire interview. Make sure that I have their attention before I say anything meaningful. Okay. So that's how we compensate for that. And then the second thing is help them follow along. Share what is your structure, and keep going back to structure. Hey. Here, I I'm I have five segments. Segment one, segment two, segment three, segment four, segment five. And then I'm talking about segment two. So use numbered lists and use structure to help them actually, like, keep track of things. However, you are thinking in structure, you want them to capture that structure in their notes. And then you wanna help them capture notes. So if you wanna help them capture notes, slow down your speech. Use pauses If you speak fast, pause. So they can finish writing. You wanna actually, like, see, okay, they finished typing and then they look at you. What's next? And you wanna actually do that. Communicate in short sentences. And don't swallow words. Okay. And then a stuff where people seem to not be accepting the direction you are taking the interview. And what do you do about that? There's, like, two types of scenarios that could be fine themselves out. One is that like the interviewer knows some information, that you don't know, And because of they have they have that extra information, they know for sure that the path that you're going down is wrong. Okay. One set of scenarios fall into that. They they are privy to more information than you about the company. Their internal information, what has been tried before. So as a result of that, they genuinely think that you're going down a wrong path, they trying to actually, like, get you in a different way. If that is the case, what you wanna do is seek out that information. Hey. Is there any any additional information I'm missing? Like, are is there any is my assumption. Is this assumption right? And that gets you extra information that they have in their head that is pushing them in a different direction. Then there are other people who act want you to give them a specific solution. And that's, like, a different set of people. And then over there, what you want to do is, again, try to actually, like, dig up, hey. What additional context you have? What assumptions are am I making? So you can't ask them for the solution, but you actually have to ask questions about contacts, and actually, like, other information that will lead you in that direction. And if they're actually trying to take it on a path, like, try to evaluate that. Okay. That's what you can do in the best in that scenario. Cool. Last thing I wanna touch on is how do you practice verbal skills? We talked about actually, like, saying, hey. Like, do deep writing, then do deep speed writing. And then what you could practice and what I make people do actually, like, the boot camp, practice this thing of thinking time and speaking time. Like, write for four minutes, then speak for four minutes. You wanna, like, think about context and motivation, write it for four minutes, and then speak it for four minutes. You wanna talk about segmentation, think for four minutes. Speak for four minutes. And then compress the writing time down. Reduce writing time to two minutes and then for four minutes. Reduce writing time to one minute, speak for four minutes. And you practice that, separate out thinking time from speaking time, and record yourself and you evaluate, how you spoke. And that's how you get better at verbal skills. Okay. And then you put together a full interview of writing plus speaking, that's how interviews are gonna be. Thinking time plus speaking time, and you wanna isolate that up. You wanna reduce the thinking time but when you start the practice, you're gonna take longer to think. So you get better. You start by writing performance and then shrink it. To by practicing recursively. Cool. Think Have anything here. No. Cool. So that's what I had for verbal skills. Yeah. I think I think the point over here that I was trying to make is that if you're trying to actually, like, practice verbal skills for leadership style questions, you wanna practice writing for four minutes and then speaking for four minutes for leadership stories to start with. But for leadership stories, you can't actually, like, say, oh, I'm gonna think for four minutes before I'm gonna speak. The expectation is that you wanna start speaking right away. That's what the expectation is. But you can actually buy yourself thirty seconds to a minute. Okay? And you want to practice the art of writing a story or thinking about a story in, like, thirty seconds to a minute. Okay. So let me see if I okay. I didn't have one. Okay. But you can any story, you can think about the arc of the story in, like, thirty seconds to a minute. So for example, the previous story that I told, about what were the time when you fell, The thirty second version of that is FB discover organizational influence got into trouble. Understood my gap was organizational influence, or and then worked on that in a few other projects and from other people. Got better at it, and then showed that I could I I I had a reputation for doing that well. That's a thirty second version of that story. And you wanna practice. You wanna get to that place. Where any story you can write the arc in one minute on you can literally type it in a minute if you have to write it. You can think that arc thirty seconds. And you wanna get there. Cool. Stop. Let's talk about mindset. I'm just gonna take a sip of water. Okay. So mindset. Let's talk about what is desirable versus undesirable traits in interviews. So we all So we all wanna show up in in interviews as our best selves. As best selves as human beings best selves as PMs, best selves as leaders. And we wanna put our best foot forward in answering questions. Okay. So we want people to see like, the best version of us interviews. But and then, like, what makes us desirable? So what is that part of our best version that makes us desirable? Coming off as being competent coming off as being confident coming off as being likable, and having social proof, makes us desirable as job candidates. And what do each of these things show up as? What is the signal for these things? Competence comes from having a good pedigree which is like, where did you previously work What products did you build? Is your pedigree? And showing strong skills that you show through the interview process. Confidence comes off from demonstrating that you have this mindset that you will figure it out. You don't have to have all the answers, but you should come off as someone who will figure out the answer. Okay? And off as having a growth mindset, hey. Like, I'm not perfect. I have some gaps, and I am always, I can close those gaps. I've shown that I can close gaps in the past. I will have new gaps, and I will close them. That's what confidence is. That you can figure out external problems and you can figure out internal problems. That's what confidence is. Okay. Likeability What makes someone likable? For someone for you to like someone, you need to be find something that you admire in that person. So if you have to be likable, other people should be able to see something in you that they admire. Something in you that they want to learn from you. I wish I was like that person in some way. I wish I could do that specific thing just as good as them. Okay. That's, like, the seed of actually likability. And then being easy to work with. And having no ego. Okay. That's what makes people likable. So if there's no guarantee that people will like me, but if people could find something that they admire in me, through a conversation, if people could find something that they wanna learn me in a conversation. If I come off as someone who's easy to work with and I come off as someone who is humble but confident, there's a higher probability that people are gonna like me. Okay? And then social proof comes from current company that you current company wants you and other companies want you. And that's what social proof is. And these things make us desirable as job Competence, confidence, likability, and social proof. And similarly, what makes us undesirable as job candidates? Not having competence, which is lack of pedigree and lack of skills, over or under confidence, overconferences, I know it all, It's easy. If only you let me do this job. I am great. You don't recognize it. I'm sure I can do this job better than you. Or I'm not sure I can do this job over and under confidence. Not likable, things that you say or do that turn people off, not being collaborative, not taking feedback, not being intellectually honest, and actually, like, having like, huge ego. It's like, hey. I should have this job. It's your if you don't take me. Like, all of these thoughts. Show up as actually, like, making us not likable. And then the reality is if you don't have other options, it also makes us undesirable. That and then it shows off as actually, like, we desperately want this job. So that's what our desirable attributes and undesirable attributes in an interview. And we want to show our best self. What gets in the way of us bringing our best selves into an interview? It's baggage past jobs and career progression that we carry along scars from rejection in previous and current job searches, negative emotions that get generated the current interview process. K. Let's talk about each of these things. How do we shed the baggage from past job experiences and career setbacks? What is baggage? Okay. So what is baggage? Let's actually start by defining that. We all have had missed opportunities. Okay. So I blew chances of actually going from an I c six to a d one in, like, two years. If I had, like, just kept my shit together. Okay. Missed opportunity. Perceived unfairness. Somebody escalated on me at some point. That actually cost me a promotion. Okay. Social comparison. We both join at the same time. That person rise rise up so fast. Bad managers or coworker relationships. Whatever they are, unhappy with the company culture. Family or financial pressure. All of these are actually, like, the baggage that we carry around. Okay? And what do they show up as? They show up as saboteur mindsets. Okay. There's this, like, survey. I got I'll send it to you guys. You can actually take it later, but I really love Shirazad's framework for saboteurs. But there's a bunch of saboteur mindsets that we all have. Like, whether it's, like, sticklers, hyperachievers, pleasers, controllers, avoiders, feeling like a victim, all these things. All of this baggage shows up as these mindsets. Okay. So for example, at some point, had a very strong victim mindset. Okay. And that victim mindset was showing up in interviews. In some form. Okay? Or it will show up in interviews. If I if I if I actually, like, carry that So what are these mindsets do? We judge ourselves. We judge other people. And we judge the situation we are in. We feel like a victim. We are focused on people pleasing. We are constantly restless. We try to control the situation and the people around us. We are worried about how things can go wrong. We are aiming for perfection. Okay. That's what the saboteur mindsets do. And what does it do an interview? What undesirable actions does it cause in an interview? Judging ourselves poorly leads to us not showing up as confident people. Judging others and situations leads to us coming off as not taking ownership and accountability. Judging other people can come off as us being arrogant. People pleasing can come off as being incompetent and desperate. Restlessness can show up as being unprincipled in decision making. Controlling can come off as being inflexible and not collaborative and not taking feedback. Worrying comes up as not being confident. Perfection comes off as not being confident and not being competent. So the Salvador mindsets show up in extremely undesirable ways in interviews. Okay. So, like, who actually, like, has his father of intelligence thinks talks about what the saboteur and the sage mindset. Saboteur mindsets of all of those things that we talked about, What's the sage mindset? Sage mindset is a radical acceptance of the situation. I can't change the past. I can't change my current situation. This is what the current situation is. You have to radically accept the situation. And then you have to understand whatever problem is deeply You have to brainstorm what the ideas are. You make principal decisions. And then you take action. That's what the sage mindset is. We do that at work, We do need to do that about our own personal lives as well and our mindset. Towards all of these baggage that we carry along. K. How do you switch from a saboteur mindset to a sage mindset? Take the Sabador survey, identify what resonates with you. Okay? It's not like some truth. Like, if it tells you you have a Sabodo does not mean that you haven't. Like, just see what signals you get, and then see if it resonates with you. Okay. There are some things that were pretty obviously resonate with me, and I actually said, okay. I think I need to work on those. Extremely high level of judgment of myself. Was what I started with. Being a victim feeling like a victim in some form. Now to tackle those. And the way that you deal with it is that every time you feel the saboteur taking over, you name it. You have to say, hey. My victim is showing up. My judge is showing up. And by naming it, you're acknowledging that that exists. And then once you acknowledge it, then your mind automatically shifts to how do I not feel like a victim. How do I not let my victim mindset take over me? That's the first part, labeling it and calling it out for it and externalizing it. It's not you who's a victim, but there's a victim mindset that is taking over you right at this in time. That's the starting point of it. The second part of it is that you visualize your saboteurs at their worst. So when I'm judging myself, I'm judging myself extremely harshly. So if I stood in the front of a mirror and then just acted out how I treat myself when my judges is at its worst, And I saw it for the first time, I was shocked at how I was treating myself like that. And am I treating my wife like that? And if I'm doing that, this like, reason for why she's scared to be around me when I'm judgmental of her. Okay. So that's the other way to actually, like, think of visualize your your saboteurs So if I'm a victim, if I'm feeling like a victim, if I look at myself in the mirror when I'm actually, like, taken over by my victim, I would see that I look pathetic. And if I see myself like that, do I want to be that person? Probably not. And that's the second thing to actually, like, deal with your saboteurs. The third thing is that our saboteurs stem from some past experiences, whatever those are, whenever they happen. And you wanna identify what those are and then debug that from there. Where did my victim mindset come from? I need to identify that to actually, like, untangle that. So my victim mindset came from this thing where, like, when I was growing up, we grew up on a middle class family. My we never lack for anything. But my brother and I, who are one year apart, always had one toy of a kind. One tennis racket, one bicycle, one cricket bat, one soccer ball, Okay. And I could never negotiate with him. My parents did not teach me how to negotiate. So we'd fight about something, and my immediate reaction would be, you take it. It's yours. That was the seed of my victim mindset. And as I grew, that I assume that that was the case. And at work, I was still holding the victim mindset. And when I realized that, that's where it's stemming from. I think realize that, hey. One, my brother is gone. Are not the same people. We don't actually operate that way. That's step one. The second thing is that all the people I'm working with I don't have that relationship with them. Two, or three, I am now a different person and I can negotiate with people I can stand up for what I want. I can actually, like, talk to people about issues that I have with them. And I don't need to feel like a victim. And that's what I had to do actually untangle having a victim mindset. And that's what you wanna do. And then you have to, like, journal to shift from of your saboteurs to a sage. Let's say that I'm panicking. About hey. How am I gonna do this, like, five hour session? I've not yet compressed my slides. Whatever it is that I might be, like, going through it yesterday night. Okay. I have, like, five x a number of slides for this stuff on my course. Like, I need to compress it down into that I can make sense in this amount of time. And I have done none of that. And I could have that thought, and I'm like, judging myself for why didn't I do this earlier? Why didn't I actually, like, spend enough time on this? It gonna be good enough? Like, I gonna come off as not actually, like, collected in that thing? All of these thoughts could be there, and I'm judging myself. How do I shift? I start by journaling. I say, okay. Hey. What emotions am I feeling? What is the real facts What are the assumptions I'm making? What actions can I take? And let people act on that now. And that's the shift actually go from a saboteur mindset to actually, like, a sage mindset. Radical reality. I don't have any slides at 5PM yesterday evening. That are composed in a way that I want for today, That's the reality. But I've thought about how do I structure these for the full day And now my action is before going to bed, what am I gonna do? When am I gonna wake up? What changes do I wanna make? And I'm gonna execute on that. And that's journaling mentally. To get to where I wanna be, going from a Salvador mindset to a sage mindset. Okay. How you do it. And then you wanna see gifts in things. Like, when things don't go wrong when things go wrong, you wanna actually, like, see the gifts in them. So for example, when I, like, fail at that point in time, there's, a gift of knowledge, which is that, hey. What knowledge do I need to gain now so that I don't find myself in that situation again? I needed to learn about organizational dynamics, navigate organizational conflict, and all of that. I got the gift of knowledge. Because of that situation. Gift of power which is that, hey. Like, I practice those muscles. In some form. And I now at a place where people view that as a strength of mine. Gift of inspiration. When that happened, I started going into Orangetheory Fitness. And in six months, I got into the best shape of my life. And I wouldn't have done that if actually, like, I was not things were going well. Okay. So that's how you shift from a Salvador mindset to a stage mindset. Then the second thing, like, all of this is dealing with package and the mindset that actually goes with it. The second thing is how do you bounce back from rejection during job interviews? So most of us have faced rejection. Here are mine. I got rejected by all top 10 US computer science PhD programs twice. In 2002 and 02/2003. I literally applied to one to 10. And I got rejected twice. I got rejected by all top 10 US MBA programs without an interview in 2010. I wanted to actually, like, leave engineering, pivot to pivot to product management, but I wanted to go to only the top 10 MBA schools. I applied to all top 10 MBA schools. I didn't get a single interview. I got rejected by Google YouTube, LinkedIn, Facebook, Yelp, 2011. And 12, somewhere there. Google declined to interview me in 2017. After six years of PMing after Yelp when I was leaving Yelp, Google declined to interview me in 2017. Until I got a job at Meta, and then some friend of mine like, created a mess, and then they wanted to interview me in 2017. These are my rejections. Okay. And there's probably, like, a lot more. I'll keep adding. Lenny rejected me for, like, Lenny fellowship or whatever, and I can actually keep stacking up the failures in some rejections that I face. Okay. They're all gonna be there. And you have to, like, deal with them. So what does this do to our psychology?  
Me: So you wanted the same pain?  
Them: It leads to unattractive behaviors. And what are those things? We have a chip on our shoulders. We are fearful of more rejection. We feel unworthy. Okay. And what does chip on your shoulder mean? It's like, let me show you how good I am. It's your loss if you don't choose me. How do you have a job and I don't? I'm better than you. Like, all of these are chips on our shoulders. And if we don't deal with that, it's gonna come through in the interview. It's gonna come through in the interview. Fear of rejection. We don't wanna go through the same thing again. Okay. I've, like, applied for four times. I've, like, gone rejected. Like, I don't wanna deal with this shit again. Like, we want to people please. We are like, hey. Just let me in. Okay. Let me in the door. Okay. Don't feel comfortable saying the things that we think because we are like, okay. They're gonna, like, reject us again. Okay. We feel like this is our only shot. That's how fear of rejection shows up in interviews. And we feel unworthy. We are like we start looking down upon ourselves as human beings. We think we are lucky to get this interview. We are lucky to get this job. All of those show up as desirable behaviors and interviews. Okay. All of this rejection actually shows up that way. So how do you actually, like, deal with this stuff? How do you deal with this? Right? So the fundamental thing to think about is you have to start by thinking about what determines how companies recruit. It all starts with company's desirability, and the macroeconomic conditions that are actually like that. So what makes companies desirable? Current compensation, their future compensation that they can give you network or quality of people, the market growth potential for that area that they're in, growth rate. All of these make a company desirium. And you think about that, what are the tiers of companies? I'm gonna go from bottom to top. The companies which are like, hey. They give you a paycheck in a PM related role. Okay. And then companies that help you get into a real product role. You have a PM title, but, actually, you don't have a real PM role. Okay. There's some companies where that happens. There are companies where you can actually, like, build real product skills. Like a real PM job. You can build a real product. Skills. And there are a bunch of companies that are stepping stones to the companies that everybody wants to work at. Okay? Yelp is a great company that actually falls into the stepping stone but great product company, like, gives people a lot of room. And it could be a stepping stone for where people wanna go. And then at any point in time, there are two buckets of companies that everybody wants to work at right now. There are companies that everybody wants to work at but they're paying future compensation. And companies like Stripe, OpenAI, Anthropic, everybody wants to work there, but you only get base pay and then all the stock is actually, like, illiquid. And then there are companies where everybody wants to work right now, pay in current compensation. Meta, Microsoft, Google, stock is liquid. You can sell every quarter. Okay. That's the tiers of companies in my perspective. On actually what they do, for people. So then how do companies screen candidates? Based on a company's desirability, they have an ideal candidate profile. Okay. If you are in this company, everybody wants to work at right and they're paying future compensation. Your Anthropic or your your OpenAI they have an ideal candidate profile, and they create filters for that. Okay. And so that that's the thing. So if you are OpenAI, you have some set list of companies that you wanna hire from. If you are Yelp, you want you are gonna have a different list of companies that you're gonna you can hire from. If you are, say, like, Dell, there's a different list set of companies that you can hire from. Okay. If you are Accenture, different set of companies that you can actually, like, hire from. So they are, like, filters that they're actually excelling based on how desirable the company is. Because they can't interview everybody, So based on how competitive they are, they're setting their filters. So that determines whether actually you are one, part of the filter or not. Because it's competition that actually, like, is dictating that. And it's not you as a full person but it's about what your current pedigree is at that point in time and what your current skill sets are at that point in time. So what do you have control over? What companies will you be desirable for at this moment in time How can you represent your work as outcomes? How do you set yourself up for the next next job? Based on your current you can't change your current pedigree. But you can change your next pedigree which will help you with your next next job. So you can think monthly steps in. How do you set yourself up for the next next job and the next next next job? And view everything as an incremental step. So I wanna talk about my incremental steps. Okay. So I was at video mining, a super small company. As an engineering engineering lead, I, like, ran all of engineering for that company. And when I made my first transition into PM, my first job was building internal tools at Yahoo. For editors who were curating content on the 200 websites at Yahoo. So I was hired in as like, an internal tools PM. Okay. From there, I did well there, earned some reputation, got some promo, and then actually, like, I moved from there a video platform role, And from there, I moved into personalization. Moving into personalization was like a thing that made me attractive to Flickr which was photo sharing inside Young. And I got a consumer facing role for the first time there. So three years, three steps, I got a consumer facing role in Flickr. Working at Flickr, had brand recognition that I got into Yelp. Yelp didn't want to interview me in 2011. Wanted to interview me in 2014. After I worked at Flickr. Personalization. And that got me a Yelp SMB role. And I did really well on the SMB role, And then when Yelp was actually doing services, I got that product lead role. And then from Yelp services, Meta was working on services, so they wanted to interview me. And I got interviews at Meta. And then once I got into Meta, I got a job in the Facebook app working on navigation. And in my first year, I'd launched, like, three pretty public things that I posted on on on in the Facebook app group and actually, like, we're very high exec visible things. That helped me get other roles in Messenger. And then I worked on this Facebook app. Navigators name discovery thing, then I got into Instagram. From Instagram, like, I worked on US twenty twenty elections, and I learned some reputation over there. That got me a role in, like, ads on the newest version of ads that they were working. And then I I'm like, okay. Hey. I wanna go back and then work on AI, So my eight years of computer vision experience early on combined with the fact that I shipped products at a bunch of different things inside Facebook, got me a role into Feyi. Which is fundamental AI research. And by being in fundamental AI research, when the GenAI org was first set up in in, like, 2022 or 2023, I was the first PM working on consumer agents at in the Gen AIR. Everything is like a stepping stone. Okay? So I was not born with a silver spoon. I didn't get, like, hey. Here's the thing. Everything became a stepping stone to the next thing. Okay. That's what I want you to think about. So I'm gonna skip this thing. The thing that so one, view everything as a stepping stone. Don't think about, hey. Like, Mara does not want me right now. Think about, hey. If I wanna get into Meta, maybe I have to take three hops to get there. What are the hops in between? And how do I actually, like, navigate that? That's what I want you to take away from it. The next thing is how to interpret a rejection. Rejection is about there's a lot of competition in the world, Externalize that. Okay? It's not judgment on me as an overall person and my full potential. It's just a comparative evaluation of my current version of pedigree and skills against others who are in the market at this specific point in time. That's the thing to internalize. It is not a judgment of your full self and your full potential. It is just a comparative evaluation of your current pedigree and your current skills against the people who are in the market right now. Okay. That's the first place to stop. There are a lot of competition, and the competition changes based on macroeconomic conditions. The companies you're trying to interview for. And then see what is the gap between me the other people who are landing at those companies. What is the deadline pedigree? What is the deadline skills? What is the deadline perception? The recruiting game that they are playing. And how do I close the gaps those things. Which parts of these can I close in this job search and which ones do I need to actually, like, close on a longer horizon? And then what companies do I shoot for based on actually, like, what I'm seeing as my current market value? And make adjustments to that. That's how can you have to, like, interpret a rejection. Cool? Last thing that I wanna touch on is managing negative emotions during interviews in some form. Oops. Sorry. So what creates negative emotions in interviews? We don't have enough time to prepare. We didn't get the right time slot. We got a bad interviewer. We were stuck in traffic. We didn't wear good fitting clothes. We are swearing too much, We didn't eat appropriately. We had back pain. Didn't sleep well. Dog was sick. Could have done better in the previous interview. Made a mistake in the current interview and the need to backtrack. I misspoke a word. I shouldn't have said this. Any of these can create negative emotions. Okay. Fundamental thing is, what do you do? The thing is to change your mindset. In sports, the match is happening. It's now and you have to do everything in your power to win it in this time window. You can't say, hey. Pause the match. I'm not in a good shape right now. I'll come start the match in thirty minutes. It's happening now. You just have to do your best. At that point in time. Okay. That's the discipline part of it to actually think about. When the plot starts, you just show up and then do the best you can.  
Me: It's a fair  
Them: That's, like, one. Second thing is that you don't have to be perfect. You just need to be better than other candidates and you need to hit a certain bar. In the thing the biggest change for me is that perfection in life is like a fleeting thing. Life is like moments, like small moments of perfection, with messiness surrounding it. And accepting that and then what you have to think about is that you just you can't aspire for perfection. You just need to hit a super high bar. And what that means is ignoring the small mistakes you make and then actually, like, trying to just do better and better at and actually hitting the bar. And then you just have to give it everything you have on that day. Just leave it all on the field on that day. And that's all you can do. Hey. If you woke up in the middle of the night, you couldn't fall asleep. You can't change that in the interview. What you can change is you're gonna do in the forty minutes that actually, like, is there. Okay? And that's what you have to do. Do you need an Agbou? Take some take two Agbou or three Agbou, whatever you need. Okay? And then just shop. Here is my pills of Advil sitting over here. Okay. Yeah. Take the pills. Whatever it like, but show up at your best self. And that's what it is. Just give everything you have. And that's what you can do. Okay. How do you do it? You focus on inputs and not on outputs. K. You do the things that are in your control and stop worrying about the things that are out of your control. You do your best in every circumstance. That's what I keep saying. The discipline of daily practice However you show up in practice, how you're gonna show up in the interview. Okay? Then make the full time count. Okay. In sports, there's a metaphor that, hey. Play for the full ninety minutes or whatever it is. Right? The exact same thing in interviews. If I made a mistake in an interview, I if I realize that at the twenty minute mark, I can redo the entire interview in the remaining twenty minutes. If I make a mistake further along, I can re go back one or two steps. And you have to make the full time count. Sometimes, maybe you have to, like, go home and then write the full response and then send it back. They may accept it or not. But make it count. Don't give up until actually, like, somebody has sent you a letter saying that, email saying that, hey. We passed on you. Until then, you want that job, give up. Okay? And then learn the practice of being a % present and then being in this moment. And then doing what you're doing right at this moment versus everything else that's happening in the Okay. So that's the set of things you practice. K. I'm gonna close on that. So that was my mindset thing. Deal with your baggage. Like, deal with your failures. And then deal with the negative emotions that happen. On, a day to day basis. Okay. Cool, folks. That's what I had. So let me I my mouse cursor is not actually, like, showing up. Thank you for showing up and then spending five hours with me on a Sunday. I hope this was valuable. I wish you all the best with interview preparation. Create your own plan. Put in the time. So, yeah, 